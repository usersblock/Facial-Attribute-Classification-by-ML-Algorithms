{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45fa2487-02fc-461a-8d41-0ccb7f683ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib  \n",
    "imageprocessing = importlib.import_module(\"JV-ImagesProcessingFunctions\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Input,Activation,Add, MaxPooling2D, MaxPooling1D, Flatten, Dense, Conv1D, Dropout\n",
    "import gc\n",
    "from ipynb.fs.full.SIFT_to_Features import SIFT_nparray_to_Features\n",
    "from tensorflow import keras\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8297c30c-2aa6-4b40-b945-610921fc0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplifies adding a layer\n",
    "def Convolution(input_tensor,filters):\n",
    "\n",
    "    x = layers.Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same', activation = 'relu')(input_tensor)\n",
    "\n",
    "    return x\n",
    "\n",
    "def Convolution1D(input_tensor,filters):\n",
    "\n",
    "    x = layers.Conv1D(filters=filters,kernel_size=(3),padding = 'same', activation = 'relu')(input_tensor)\n",
    "\n",
    "    return x\n",
    "\n",
    "#Simple CNN model\n",
    "#Conv stands for neural network layers of (x,y). x standing for the input layers and y standing for how many filter layers there are\n",
    "#maxp is a pooling layer that reduces the number of nodes of the next layer\n",
    "#flatten changes the previous layer to a 1 dimensional layer\n",
    "#dense layers have each node connected to every node in the previous layer. In this case, we have 3 dense layers of differing weights representing\n",
    "#age, gender, and race. While all previous layers have collected features, dense layers calculate based on these collected features.\n",
    "#They then send their calculations to the final dense layer to determine classification\n",
    "#Binary Crossentropy = Classifies based on a binary value\n",
    "#Sparse Categorical Crossentropy = Classifies based on an integer value with more than 2 possible values\n",
    "def Simplemodel(input_shape,column):\n",
    "  losstype = \"\"\n",
    "  outputn = 0\n",
    "  if(column == 'age'):\n",
    "    losstype = \"sparse_categorical_crossentropy\"\n",
    "    outputn = 9\n",
    "  if(column == 'gender'):\n",
    "    losstype = \"binary_crossentropy\"\n",
    "    outputn = 1\n",
    "  if(column == 'race'):\n",
    "    losstype = \"sparse_categorical_crossentropy\"\n",
    "    outputn = 5\n",
    "\n",
    "\n",
    "  inputs = Input((input_shape))\n",
    "\n",
    "  conv_1= Convolution(inputs,32)\n",
    "\n",
    "  maxp_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)\n",
    "\n",
    "  conv_2 = Convolution(maxp_1,64)\n",
    "\n",
    "  maxp_2 = MaxPooling2D(pool_size = (2, 2)) (conv_2)\n",
    "\n",
    "  conv_3 = Convolution(maxp_2,64)\n",
    "\n",
    "  maxp_3 = MaxPooling2D(pool_size = (2, 2)) (conv_3)\n",
    "\n",
    "  conv_4 = Convolution(maxp_3,64)\n",
    "\n",
    "  maxp_4 = MaxPooling2D(pool_size = (2, 2)) (conv_4)\n",
    "\n",
    "  conv_5 = Convolution(maxp_4,64)\n",
    "\n",
    "  flatten= Flatten() (conv_5)\n",
    "\n",
    "  dense_1= Dense(64,activation='relu')(flatten)\n",
    "\n",
    "  output_1= Dense(outputn,activation=\"sigmoid\",name='out')(dense_1)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[output_1])\n",
    "\n",
    "  model.compile(loss=[losstype], optimizer=\"Adam\",\n",
    "\n",
    "  metrics=[\"accuracy\"])\n",
    "\n",
    "  return model\n",
    "\n",
    "def Simplemodel1D(input_shape,column):\n",
    "  losstype = \"\"\n",
    "  outputn = 0\n",
    "  if(column == 'age'):\n",
    "    losstype = \"sparse_categorical_crossentropy\"\n",
    "    outputn = 9\n",
    "  if(column == 'gender'):\n",
    "    losstype = \"binary_crossentropy\"\n",
    "    outputn = 1\n",
    "  if(column == 'race'):\n",
    "    losstype = \"sparse_categorical_crossentropy\"\n",
    "    outputn = 5\n",
    "\n",
    "  inputs = Input((input_shape))\n",
    "\n",
    "  conv_1= Convolution1D(inputs,32)\n",
    "\n",
    "  maxp_1 = MaxPooling1D(pool_size = 2) (conv_1)\n",
    "\n",
    "  conv_2 = Convolution1D(maxp_1,64)\n",
    "\n",
    "  maxp_2 = MaxPooling1D(pool_size = 2) (conv_2)\n",
    "\n",
    "  conv_3 = Convolution1D(maxp_2,64)\n",
    "\n",
    "  maxp_3 = MaxPooling1D(pool_size = 2) (conv_3)\n",
    "\n",
    "  conv_4 = Convolution1D(maxp_3,64)\n",
    "\n",
    "  maxp_4 = MaxPooling1D(pool_size = 2) (conv_4)\n",
    "\n",
    "  conv_5 = Convolution1D(maxp_4,64)\n",
    "\n",
    "  flatten= Flatten() (conv_5)\n",
    "\n",
    "  dense_1= Dense(64,activation='relu')(flatten)\n",
    "\n",
    "  output_1= Dense(outputn,activation=\"sigmoid\",name='out')(dense_1)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[output_1])\n",
    "\n",
    "  model.compile(loss=[losstype], optimizer=\"Adam\",\n",
    "\n",
    "  metrics=[\"accuracy\"])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "444c2bfb-d532-4286-9fca-17a8e4b3990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and convert for model\n",
    "data = np.load('../data/raw/UnbalancedRaw/npimagearrays.npy',allow_pickle=True)\n",
    "filelabels = pd.read_csv('../data/raw/UnbalancedRaw/npimagefilelabels.csv').loc[:,['file','age']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, filelabels, test_size=0.33, random_state=42)\n",
    "\n",
    "y_testnp = np.asarray(y_test.loc[:,'age'])\n",
    "\n",
    "y_trainnp = np.asarray(y_train.loc[:,'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcd71f9c-af0b-4aed-a3e4-a36b0c453d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectMask(nparraytrain,nparraytest,select = 0):\n",
    "    \"\"\"\n",
    "    No mask option Select = [1< or >10]\n",
    "    \"\"\"\n",
    "    X_train_mask = nparraytrain\n",
    "    X_test_mask = nparraytest\n",
    "    \"\"\"\n",
    "    Sobel filter on image picture channel\n",
    "    \"\"\"\n",
    "    if(select == 1):\n",
    "        X_train_mask = imageprocessing.sobelFilterTypes(nparraytrain)[0]\n",
    "        X_test_mask = imageprocessing.sobelFilterTypes(nparraytest)[0]\n",
    "    \"\"\"\n",
    "    Sobel filter on image picture hsv\n",
    "    \"\"\"\n",
    "    if(select == 2):\n",
    "        X_train_mask = imageprocessing.sobelFilterTypes(nparraytrain)[1]\n",
    "        X_test_mask = imageprocessing.sobelFilterTypes(nparraytest)[1]\n",
    "    \"\"\"\n",
    "    returns two numpy arrays with pictures in black and white and with the edges define using Roberts filter\n",
    "    \"\"\"\n",
    "    if(select == 3):\n",
    "        X_train_mask = imageprocessing.robertsSobelEdges(nparraytrain)[0]\n",
    "        X_test_mask = imageprocessing.robertsSobelEdges(nparraytest)[0]\n",
    "    \"\"\"\n",
    "    returns two numpy arrays with pictures in black and white and with the edges define using Sobel filter\n",
    "    \"\"\"\n",
    "    if(select == 4):\n",
    "        X_train_mask = imageprocessing.robertsSobelEdges(nparraytrain)[1]\n",
    "        X_test_mask = imageprocessing.robertsSobelEdges(nparraytest)[1]\n",
    "    \"\"\"\n",
    "    This fucntion increases the exposure of each picture and it returns a numpy\n",
    "    array of the modified images. The images are in color\n",
    "    \"\"\"\n",
    "    if(select == 5):\n",
    "        X_train_mask = imageprocessing.exposure_(nparraytrain)\n",
    "        X_test_mask = imageprocessing.exposure_(nparraytest)\n",
    "\n",
    "    \"\"\"\n",
    "    This function gamma corrects the image\n",
    "    \"\"\"\n",
    "    if(select == 6):\n",
    "        X_train_mask = imageprocessing.gammaLogaritmictCorrection(nparraytrain)[0]\n",
    "        X_test_mask = imageprocessing.gammaLogaritmictCorrection(nparraytest)[0]\n",
    "    \"\"\"\n",
    "    This function logarithmic corrects the image\n",
    "    \"\"\"\n",
    "    if(select == 7):\n",
    "        X_train_mask = imageprocessing.gammaLogaritmictCorrection(nparraytrain)[1]\n",
    "        X_test_mask = imageprocessing.gammaLogaritmictCorrection(nparraytest)[1]\n",
    "    \"\"\"\n",
    "    This function rescales the image\n",
    "    \"\"\"\n",
    "    if(select == 8):\n",
    "        X_train_mask = imageprocessing.histogramEqualizer(nparraytrain)[0]\n",
    "        X_test_mask = imageprocessing.histogramEqualizer(nparraytest)[0]\n",
    "    \"\"\"\n",
    "    This function equalizes the image\n",
    "    \"\"\"\n",
    "    if(select == 9):\n",
    "        X_train_mask = imageprocessing.histogramEqualizer(nparraytrain)[1]\n",
    "        X_test_mask = imageprocessing.histogramEqualizer(nparraytest)[1]\n",
    "    \"\"\"\n",
    "    This function adapthis the image\n",
    "    \"\"\"\n",
    "    if(select == 10):\n",
    "        X_train_mask = imageprocessing.histogramEqualizer(nparraytrain)[2]\n",
    "        X_test_mask = imageprocessing.histogramEqualizer(nparraytest)[2]\n",
    "    return X_train_mask,X_test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3489eec-3e93-433b-b511-e7ad23635f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessnparrays(X_train,\n",
    "                       X_test,\n",
    "                       y_train,\n",
    "                       y_test,\n",
    "                       mask = 0,\n",
    "                       sift = False,\n",
    "                       vocab = 200,\n",
    "                       pca = False,\n",
    "                       n_components = 200 ,\n",
    "                       rfs = False,\n",
    "                       n_estimators = 20):\n",
    "    X_train, X_test = SelectMask(X_train,X_test,select = mask)\n",
    "    if(sift):\n",
    "        X_train, X_test = SIFT_nparray_to_Features(X_train,X_test,nvocab = vocab)\n",
    "        if(pca):\n",
    "            pcax = PCA(n_components = n_components)\n",
    "            pcax.fit(X_train)\n",
    "            X_train = pcax.transform(X_train)\n",
    "            X_test = pcax.transform(X_test)\n",
    "        if(rfs):\n",
    "            selector = SelectFromModel(RandomForestClassifier(n_estimators = n_estimators))\n",
    "            selector.fit(X_train, y_train)\n",
    "            X_train = X_train[:,selector.get_support()]\n",
    "            X_test = X_test[:,selector.get_support()]\n",
    "    else:\n",
    "        if(pca or rfs):\n",
    "            X_train = X_train.reshape(len(X_train),200*200*3)\n",
    "            X_test = X_test.reshape(len(X_test),200*200*3)\n",
    "            if(pca):\n",
    "                pcax = PCA(n_components = n_components)\n",
    "                pcax.fit(X_train)\n",
    "                X_train = pcax.transform(X_train)\n",
    "                X_test = pcax.transform(X_test)\n",
    "            if(rfs):\n",
    "                selector = SelectFromModel(RandomForestClassifier(n_estimators = n_estimators))\n",
    "                selector.fit(X_train, y_train)\n",
    "                X_train = X_train[:,selector.get_support()]\n",
    "                X_test = X_test[:,selector.get_support()]\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8118a7c-22b6-4de3-a749-aba9fe50037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "Modelsimple=Simplemodel((200,200,3),'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425576c7-145c-43d3-925b-3fe35a450a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Modelsift=Simplemodel1D((200,1))\n",
    "Modelsift.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cc7f54a-7a63-45cd-b8bb-f3b0e6a94c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionmatrices = []\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef5fb6b5-cf4c-4d0d-8883-dc41a84756df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new,X_test_new,y_train_new,y_test_new = Preprocessnparrays(X_train[:1000],\n",
    "                                                                       X_test[:100],\n",
    "                                                                       y_trainnp[:1000],\n",
    "                                                                       y_testnp[:100],\n",
    "                                                                       mask = 0,\n",
    "                                                                       sift = True,\n",
    "                                                                       vocab = 200,\n",
    "                                                                       pca = False,\n",
    "                                                                       n_components = 200 ,\n",
    "                                                                       rfs = False,\n",
    "                                                                       n_estimators = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7c3fb3e1-19f3-43d9-a383-1a3d85f63203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200, 200, 1), dtype=float64, numpy=\n",
       "array([[[0.01616904],\n",
       "        [0.02218374],\n",
       "        [0.02235638],\n",
       "        ...,\n",
       "        [0.01753779],\n",
       "        [0.00620054],\n",
       "        [0.01568627]],\n",
       "\n",
       "       [[0.02660279],\n",
       "        [0.02529322],\n",
       "        [0.02146884],\n",
       "        ...,\n",
       "        [0.02772968],\n",
       "        [0.02111829],\n",
       "        [0.00392157]],\n",
       "\n",
       "       [[0.02772968],\n",
       "        [0.02616013],\n",
       "        [0.02111829],\n",
       "        ...,\n",
       "        [0.03100272],\n",
       "        [0.04340381],\n",
       "        [0.00392157]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.09835244],\n",
       "        [0.1464169 ],\n",
       "        [0.11154088],\n",
       "        ...,\n",
       "        [0.02777107],\n",
       "        [0.03970286],\n",
       "        [0.03529412]],\n",
       "\n",
       "       [[0.08041607],\n",
       "        [0.13476737],\n",
       "        [0.11846124],\n",
       "        ...,\n",
       "        [0.04544435],\n",
       "        [0.0570989 ],\n",
       "        [0.05882353]],\n",
       "\n",
       "       [[0.07058824],\n",
       "        [0.1254902 ],\n",
       "        [0.11764706],\n",
       "        ...,\n",
       "        [0.01148196],\n",
       "        [0.01176471],\n",
       "        [0.        ]]])>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(X_train_new, axis=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "974505a9-cea5-4091-894d-d3c0feaa0388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 7ms/step - loss: 37.0466 - accuracy: 0.2840 - val_loss: 9.8169 - val_accuracy: 0.2900\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 5.5419 - accuracy: 0.3280 - val_loss: 5.0597 - val_accuracy: 0.3000\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.8647 - accuracy: 0.3870 - val_loss: 3.2466 - val_accuracy: 0.2900\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 2.2009 - accuracy: 0.4220 - val_loss: 2.8888 - val_accuracy: 0.3500\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7640 - accuracy: 0.4680 - val_loss: 2.7858 - val_accuracy: 0.3700\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4522 - accuracy: 0.5360 - val_loss: 2.6538 - val_accuracy: 0.3600\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2387 - accuracy: 0.5660 - val_loss: 2.7030 - val_accuracy: 0.3200\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0399 - accuracy: 0.6380 - val_loss: 2.8154 - val_accuracy: 0.3200\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9510 - accuracy: 0.6730 - val_loss: 2.7708 - val_accuracy: 0.2900\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.8319 - accuracy: 0.7070 - val_loss: 2.7463 - val_accuracy: 0.3300\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    print(i)\n",
    "    X_train_new,X_test_new,y_train_new,y_test_new = Preprocessnparrays(X_train[:1000],\n",
    "                                                                       X_test[:100],\n",
    "                                                                       y_trainnp[:1000],\n",
    "                                                                       y_testnp[:100],\n",
    "                                                                       mask = 0,\n",
    "                                                                       sift = True,\n",
    "                                                                       vocab = 200,\n",
    "                                                                       pca = True,\n",
    "                                                                       n_components = 200 ,\n",
    "                                                                       rfs = True,\n",
    "                                                                       n_estimators = 20)\n",
    "    \n",
    "    #Creating the model\n",
    "    Type = 'age'\n",
    "    Modelsimple = ''\n",
    "    if(len(X_train_new.shape)==3):\n",
    "        X_train_new = tf.expand_dims(X_train_new, axis=-1)\n",
    "        X_test_new = tf.expand_dims(X_test_new, axis=-1)\n",
    "        Modelsimple=Simplemodel(X_train_new[0].shape,Type)\n",
    "    elif(len(X_train_new.shape)==2):\n",
    "        X_train_new = tf.expand_dims(X_train_new, axis=-1)\n",
    "        X_test_new = tf.expand_dims(X_test_new, axis=-1)\n",
    "        Modelsimple=Simplemodel1D(X_train_new[0].shape,Type)\n",
    "    else:\n",
    "        Modelsimple=Simplemodel(X_train_new[0].shape,Type)\n",
    "    \n",
    "    if(Type == 'age'):\n",
    "       y_test_new = y_test_new - 1\n",
    "       y_train_new = y_train_new - 1\n",
    "    \n",
    "    History = Modelsimple.fit(X_train_new,y_train_new,validation_data=(X_test_new,y_test_new),epochs=10)\n",
    "    History.history\n",
    "    \n",
    "    histories.append(History.history)\n",
    "    \n",
    "    ypred = Modelsimple.predict(X_test_new)\n",
    "    \n",
    "    confusionmatrices.append(confusion_matrix(np.argmax(ypred, axis=-1),y_test_new))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
