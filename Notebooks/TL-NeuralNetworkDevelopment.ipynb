{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb5bbb8b-3ea1-47f8-b973-ea1addfd38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score,f1_score\n",
    "from keras import Model\n",
    "from tensorflow.keras.layers import Input,Activation,Add, MaxPooling2D, MaxPooling1D, Flatten, Dense, Conv1D, Dropout\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from skimage import color\n",
    "from skimage import filters\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09f2dc63-e19e-456f-b6da-57e50c7d980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robertsSobelEdges(imagesArray):\n",
    "    \"\"\"\n",
    "    returns two numpy arrays with pictures in black and white and with the edges define using Roberts filter\n",
    "    on the first one and the Sobel filter on the second one. The images are in black and white\n",
    "    \"\"\"\n",
    "    sobel_ = []\n",
    "    for image in imagesArray:\n",
    "        grayImg = color.rgb2gray(image)\n",
    "        edge_sobel = filters.sobel(grayImg)\n",
    "        sobel_.append(edge_sobel)\n",
    "    return np.array(sobel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48a9d507-00c6-4497-afbb-90dc1a20a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the label type\n",
    "Labeltype = 'age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "485b943f-1435-4b58-986b-6819542fb635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=5, n=6093 (11.111%)\n",
      "Class=2, n=6093 (11.111%)\n",
      "Class=6, n=6093 (11.111%)\n",
      "Class=0, n=6093 (11.111%)\n",
      "Class=8, n=6093 (11.111%)\n",
      "Class=7, n=6093 (11.111%)\n",
      "Class=3, n=6093 (11.111%)\n",
      "Class=4, n=6093 (11.111%)\n",
      "Class=1, n=6093 (11.111%)\n",
      "Class=8, n=1111 (2.026%)\n",
      "Class=0, n=1111 (2.026%)\n",
      "Class=6, n=1111 (2.026%)\n",
      "Class=7, n=1111 (2.026%)\n",
      "Class=2, n=1111 (2.026%)\n",
      "Class=3, n=1111 (2.026%)\n",
      "Class=5, n=1111 (2.026%)\n",
      "Class=1, n=1111 (2.026%)\n",
      "Class=4, n=1111 (2.026%)\n"
     ]
    }
   ],
   "source": [
    "# Import image labels and paths to dataframe\n",
    "mypath = \"../data/raw/CroppedImages/\"\n",
    "filenames = np.array([f for f in listdir(mypath) if isfile(join(mypath, f))])\n",
    "splitcolumns = [x.split('_')[0:3] + [mypath + x] for x in filenames if x.count('_') == 3]\n",
    "filecolumns = ['age','gender','race','file']\n",
    "filedf = pd.DataFrame(data = splitcolumns, columns = filecolumns).astype({'age': 'int', 'gender': 'int', 'race': 'int'})\n",
    "\n",
    "# Convert age to appropriate labels\n",
    "filedf['age']=np.where((filedf.age<3), 0, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=3) & (filedf.age<6)), 1, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=6) & (filedf.age<9)), 2, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=9) & (filedf.age<12)), 3, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=12) & (filedf.age<21)), 4, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=21) & (filedf.age<36)), 5, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=36) & (filedf.age<51)), 6, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=51) & (filedf.age<80)), 7, filedf.age)\n",
    "filedf['age']=np.where((filedf.age>=80), 8, filedf.age)\n",
    "\n",
    "dfx = filedf.loc[:,'file']\n",
    "dfy = filedf.loc[:,Labeltype]\n",
    "\n",
    "# Get Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfx, dfy, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get Train/Test/Validation dataset 0.25 * 8 = 0.2\n",
    "X_train_2, X_val, y_train_2, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Encode training labels and initialize random over sampler\n",
    "yencoded = LabelEncoder().fit_transform(y_train_2)\n",
    "oversample = RandomOverSampler()\n",
    "\n",
    "# Over sample until training classes are balanced\n",
    "X_train_balanced, y_train_balanced = oversample.fit_resample(np.array(X_train_2).reshape(-1,1), yencoded)\n",
    "\n",
    "# Of all classes, proportionally sample 10000\n",
    "dxy = {'file': X_train_balanced.reshape(len(X_train_balanced)), 'label': y_train_balanced}\n",
    "dfbalanced = pd.DataFrame(data = dxy)\n",
    "balancedsamples = int(10000/len(set(dfbalanced.loc[:,'label'])))\n",
    "dfbalancedsubset = dfbalanced.groupby('label', group_keys=False).apply(lambda x: x.sample(balancedsamples)).sample(frac=1)\n",
    "\n",
    "# Count and print balanced classes\n",
    "counter = Counter(y_train_balanced)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_balanced) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "\n",
    "# Count and print balanced classes subsets (Total should be 10000)\n",
    "counter = Counter(dfbalancedsubset.loc[:,'label'])\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_balanced) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a78082cb-bd1f-4cad-94f9-dff5cf19deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training images\n",
    "train_img_container = []\n",
    "for i in dfbalancedsubset.loc[:,'file']:\n",
    "    img = cv2.imread(i)\n",
    "    train_img_container.append(img)\n",
    "train_img_container = np.array(train_img_container)\n",
    "\n",
    "# Get validation images\n",
    "validation_img_container = []\n",
    "for i in X_val:\n",
    "    img = cv2.imread(i)\n",
    "    validation_img_container.append(img)\n",
    "validation_img_container = np.array(validation_img_container)\n",
    "\n",
    "# Get testing images\n",
    "test_img_container = []\n",
    "for i in X_test:\n",
    "    img = cv2.imread(i)\n",
    "    test_img_container.append(img)\n",
    "test_img_container = np.array(test_img_container)\n",
    "\n",
    "# Convert images to sobel edges\n",
    "train_img_container = robertsSobelEdges(train_img_container)\n",
    "validation_img_container = robertsSobelEdges(validation_img_container)\n",
    "test_img_container = robertsSobelEdges(test_img_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20e19a87-ef77-4dec-897a-92ddc70b519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand array dimensions to 4D so that they may be used as inputs\n",
    "X_train_expand = tf.expand_dims(train_img_container, axis=-1)\n",
    "X_val_expand = tf.expand_dims(validation_img_container, axis=-1)\n",
    "X_test_expand = tf.expand_dims(test_img_container, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20bc3aaa-2343-4481-9940-b36142abaa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick number of final nodes based on label picked\n",
    "Nlabels = -1\n",
    "if(Labeltype == 'age'):\n",
    "    Nlabels = 9\n",
    "if(Labeltype == 'gender'):\n",
    "    Nlabels = 2\n",
    "if(Labeltype == 'race'):\n",
    "    Nlabels = 5\n",
    "\n",
    "# Model creation\n",
    "CNNmodel = models.Sequential()\n",
    "CNNmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=X_train_new[0].shape))\n",
    "CNNmodel.add(layers.MaxPooling2D((2, 2)))\n",
    "CNNmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "CNNmodel.add(layers.MaxPooling2D((2, 2)))\n",
    "CNNmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "CNNmodel.add(layers.MaxPooling2D((2, 2)))\n",
    "CNNmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "CNNmodel.add(layers.MaxPooling2D((2, 2)))\n",
    "CNNmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "CNNmodel.add(layers.MaxPooling2D((2, 2)))\n",
    "CNNmodel.add(layers.Flatten())\n",
    "CNNmodel.add(layers.Dense(64, activation='relu'))\n",
    "CNNmodel.add(layers.Dense(Nlabels))\n",
    "CNNmodel.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "100322b5-40e6-41e3-bbe9-77a403840b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 154s 491ms/step - loss: 1.7122 - accuracy: 0.3326 - val_loss: 1.6005 - val_accuracy: 0.3516\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 173s 552ms/step - loss: 1.3092 - accuracy: 0.4834 - val_loss: 1.5145 - val_accuracy: 0.3968\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 177s 567ms/step - loss: 1.1428 - accuracy: 0.5604 - val_loss: 1.3160 - val_accuracy: 0.4944\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 174s 558ms/step - loss: 0.9797 - accuracy: 0.6288 - val_loss: 1.4884 - val_accuracy: 0.4185\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 173s 554ms/step - loss: 0.8407 - accuracy: 0.6848 - val_loss: 1.6032 - val_accuracy: 0.4062\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 174s 555ms/step - loss: 0.7106 - accuracy: 0.7305 - val_loss: 1.4950 - val_accuracy: 0.4590\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 173s 554ms/step - loss: 0.6217 - accuracy: 0.7664 - val_loss: 1.7600 - val_accuracy: 0.4020\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 171s 545ms/step - loss: 0.5427 - accuracy: 0.7988 - val_loss: 1.8213 - val_accuracy: 0.4351\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 179s 571ms/step - loss: 0.4614 - accuracy: 0.8284 - val_loss: 1.8056 - val_accuracy: 0.4664\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 165s 527ms/step - loss: 0.4097 - accuracy: 0.8496 - val_loss: 1.9801 - val_accuracy: 0.4529\n"
     ]
    }
   ],
   "source": [
    "# Validation training and testing\n",
    "val_history = CNNmodel.fit(X_train_expand, dfbalancedsubset.loc[:,'label'], epochs=10, validation_data=(X_val_expand, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e3f2be4-5ed7-4b0b-8b57-9b2281b2e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3516135811805725, 0.39675173163414, 0.4944104552268982, 0.4184771180152893, 0.4062434136867523, 0.4589748978614807, 0.40202489495277405, 0.4351402521133423, 0.4663573205471039, 0.4528580605983734]\n",
      "[[212  33   4   2   3   6   1   3   1]\n",
      " [ 76  85  33  18  18  30  11   7   1]\n",
      " [  6  14  14  16  14  23   6   3   0]\n",
      " [  4  13  22  21  28  50  18  10   3]\n",
      " [  2   5  11  23 107 339  48  19   1]\n",
      " [  5   5   7   8 113 997 213  93   4]\n",
      " [  2   2   4   3  42 505 345 249  20]\n",
      " [  0   0   0   1   8 107 143 296  45]\n",
      " [  1   0   0   0   3  16  21  49  70]]\n"
     ]
    }
   ],
   "source": [
    "# Get validation accuracy and confusion matrix\n",
    "val_accuracy = val_history.history['val_accuracy']\n",
    "ypred = CNNmodel.predict(X_val_expand)\n",
    "valconmatrix = confusion_matrix(np.argmax(ypred, axis=-1),y_val)\n",
    "print(val_accuracy)\n",
    "print(valconmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9551ffe-83da-493a-bc7f-c7ea5b498f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46150601139000214\n",
      "[[224  27   2   0   3   7   1   2   0]\n",
      " [ 97  86  33   9  19  32   9   5   1]\n",
      " [  2  13  33  18  23  27   8   7   2]\n",
      " [  0   7  13  15  29  73   7  12   2]\n",
      " [  1  14  19  16 102 347  59  37   4]\n",
      " [  2   1   4   4  91 973 200  94   1]\n",
      " [  1   2   3   2  23 484 368 247  12]\n",
      " [  1   0   0   0  14 110 124 331  54]\n",
      " [  0   0   0   0   0  11  17  64  56]]\n"
     ]
    }
   ],
   "source": [
    "# Get test accuracy and confusion matrix\n",
    "ypred = CNNmodel.predict(X_test_expand)\n",
    "testconmatrix = confusion_matrix(np.argmax(ypred, axis=-1),y_test)\n",
    "test_accuracy = accuracy_score(y_test, np.argmax(ypred, axis=-1))\n",
    "print(test_accuracy)\n",
    "print(testconmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96133389-d0f9-4bf7-b82e-2df9b430b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simplifies adding a layer\n",
    "def Convolution(input_tensor,filters):\n",
    "\n",
    "    x = layers.Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same', activation = 'relu')(input_tensor)\n",
    "\n",
    "    return x\n",
    "\n",
    "def Convolution1D(input_tensor,filters):\n",
    "\n",
    "    x = layers.Conv1D(filters=filters,kernel_size=(3),padding = 'same', activation = 'relu')(input_tensor)\n",
    "\n",
    "    return x\n",
    "\n",
    "#Simple CNN model\n",
    "#Conv stands for neural network layers of (x,y). x standing for the input layers and y standing for how many filter layers there are\n",
    "#maxp is a pooling layer that reduces the number of nodes of the next layer\n",
    "#flatten changes the previous layer to a 1 dimensional layer\n",
    "#dense layers have each node connected to every node in the previous layer. In this case, we have 3 dense layers of differing weights representing\n",
    "#age, gender, and race. While all previous layers have collected features, dense layers calculate based on these collected features.\n",
    "#They then send their calculations to the final dense layer to determine classification\n",
    "#Binary Crossentropy = Classifies based on a binary value\n",
    "#Sparse Categorical Crossentropy = Classifies based on an integer value with more than 2 possible values\n",
    "def Simplemodel(input_shape,column):\n",
    "  losstype = \"\"\n",
    "  outputn = 0\n",
    "  if(column == 'age'):\n",
    "    losstype = \"sparse_categorical_crossentropy\"\n",
    "    outputn = 9\n",
    "  if(column == 'gender'):\n",
    "    losstype = \"binary_crossentropy\"\n",
    "    outputn = 1\n",
    "  if(column == 'race'):\n",
    "    losstype = \"sparse_categorical_crossentropy\"\n",
    "    outputn = 5\n",
    "\n",
    "\n",
    "  inputs = Input((input_shape))\n",
    "\n",
    "  conv_1= Convolution(inputs,32)\n",
    "\n",
    "  maxp_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)\n",
    "\n",
    "  conv_2 = Convolution(maxp_1,64)\n",
    "\n",
    "  maxp_2 = MaxPooling2D(pool_size = (2, 2)) (conv_2)\n",
    "\n",
    "  conv_3 = Convolution(maxp_2,64)\n",
    "\n",
    "  maxp_3 = MaxPooling2D(pool_size = (2, 2)) (conv_3)\n",
    "\n",
    "  conv_4 = Convolution(maxp_3,64)\n",
    "\n",
    "  maxp_4 = MaxPooling2D(pool_size = (2, 2)) (conv_4)\n",
    "\n",
    "  conv_5 = Convolution(maxp_4,64)\n",
    "\n",
    "  flatten= Flatten() (conv_5)\n",
    "\n",
    "  dense_1= Dense(64,activation='relu')(flatten)\n",
    "\n",
    "  output_1= Dense(outputn,activation=\"sigmoid\",name='out')(dense_1)\n",
    "\n",
    "  model = Model(inputs=[inputs], outputs=[output_1])\n",
    "\n",
    "  model.compile(loss=[losstype], optimizer=\"Adam\",\n",
    "\n",
    "  metrics=[\"accuracy\"])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e763bcb-c57e-43f0-b46f-c7d1957c7794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=6807 (20.000%)\n",
      "Class=1, n=6807 (20.000%)\n",
      "Class=4, n=6807 (20.000%)\n",
      "Class=2, n=6807 (20.000%)\n",
      "Class=3, n=6807 (20.000%)\n",
      "Class=4, n=2000 (5.876%)\n",
      "Class=1, n=2000 (5.876%)\n",
      "Class=0, n=2000 (5.876%)\n",
      "Class=3, n=2000 (5.876%)\n",
      "Class=2, n=2000 (5.876%)\n"
     ]
    }
   ],
   "source": [
    "#Import image labels and paths to dataframe\n",
    "mypath = \"../data/raw/CroppedImages/\"\n",
    "filenames = np.array([f for f in listdir(mypath) if isfile(join(mypath, f))])\n",
    "splitcolumns = [x.split('_')[0:3] + [mypath + x] for x in filenames if x.count('_') == 3]\n",
    "filecolumns = ['age','gender','race','file']\n",
    "filedf = pd.DataFrame(data = splitcolumns, columns = filecolumns).astype({'age': 'int', 'gender': 'int', 'race': 'int'})\n",
    "\n",
    "filedf['age']=np.where((filedf.age<3), 0, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=3) & (filedf.age<6)), 1, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=6) & (filedf.age<9)), 2, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=9) & (filedf.age<12)), 3, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=12) & (filedf.age<21)), 4, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=21) & (filedf.age<36)), 5, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=36) & (filedf.age<51)), 6, filedf.age)\n",
    "filedf['age']=np.where(((filedf.age>=51) & (filedf.age<80)), 7, filedf.age)\n",
    "filedf['age']=np.where((filedf.age>=80), 8, filedf.age)\n",
    "\n",
    "dfx = filedf.loc[:,'file']\n",
    "dfy = filedf.loc[:,'race']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfx, dfy, test_size=0.33, random_state=42)\n",
    "\n",
    "yencoded = LabelEncoder().fit_transform(y_train)\n",
    "oversample = RandomOverSampler()\n",
    "X_train_balanced, y_train_balanced = oversample.fit_resample(np.array(X_train).reshape(-1,1), yencoded)\n",
    "\n",
    "counter = Counter(y_train_balanced)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_balanced) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "\n",
    "y_train_balanced.shape\n",
    "\n",
    "dxy = {'file': X_train_balanced.reshape(len(X_train_balanced)), 'label': y_train_balanced}\n",
    "dfbalanced = pd.DataFrame(data = dxy)\n",
    "balancedsamples = int(10000/len(set(dfbalancedsubset.loc[:,'label'])))\n",
    "dfbalancedsubset = dfbalanced.groupby('label', group_keys=False).apply(lambda x: x.sample(balancedsamples)).sample(frac=1)\n",
    "\n",
    "counter = Counter(dfbalancedsubset.loc[:,'label'])\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_balanced) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d3807d0-7b34-4179-9498-42b55e27083a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancedsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e217539e-7737-4d4e-ad06-59735702d9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33330</th>\n",
       "      <td>../data/raw/CroppedImages/25_0_4_2017011715163...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18768</th>\n",
       "      <td>../data/raw/CroppedImages/52_0_1_2017011716101...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>../data/raw/CroppedImages/3_0_0_20170110212559...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33315</th>\n",
       "      <td>../data/raw/CroppedImages/7_1_4_20161223225914...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27171</th>\n",
       "      <td>../data/raw/CroppedImages/26_1_3_2017011919225...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    file  label\n",
       "33330  ../data/raw/CroppedImages/25_0_4_2017011715163...      4\n",
       "18768  ../data/raw/CroppedImages/52_0_1_2017011716101...      1\n",
       "1680   ../data/raw/CroppedImages/3_0_0_20170110212559...      0\n",
       "33315  ../data/raw/CroppedImages/7_1_4_20161223225914...      4\n",
       "27171  ../data/raw/CroppedImages/26_1_3_2017011919225...      3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfbalancedsubset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8c98982-8946-4528-aff2-0592ca8700c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_container = []\n",
    "for i in dfbalancedsubset.loc[:,'file']:\n",
    "    img = cv2.imread(i)\n",
    "    train_img_container.append(img)\n",
    "train_img_container = np.array(train_img_container)\n",
    "test_img_container = []\n",
    "for i in X_test:\n",
    "    img = cv2.imread(i)\n",
    "    test_img_container.append(img)\n",
    "test_img_container = np.array(test_img_container)\n",
    "train_img_container = robertsSobelEdges(train_img_container)\n",
    "test_img_container = robertsSobelEdges(test_img_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92e6eff4-2251-430c-967d-ee72dc8408fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = tf.expand_dims(train_img_container, axis=-1)\n",
    "X_test_new = tf.expand_dims(test_img_container, axis=-1)\n",
    "Modelsimple=Simplemodel(X_train_new[0].shape,'race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "08a0a2ad-23a2-407b-b45f-4e6afda21458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 233s 744ms/step - loss: 1.4130 - accuracy: 0.3807 - val_loss: 1.2213 - val_accuracy: 0.5513\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 241s 770ms/step - loss: 1.0602 - accuracy: 0.5859 - val_loss: 1.0903 - val_accuracy: 0.5870\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 236s 753ms/step - loss: 0.8732 - accuracy: 0.6682 - val_loss: 1.0445 - val_accuracy: 0.6234\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 238s 760ms/step - loss: 0.6889 - accuracy: 0.7491 - val_loss: 1.0520 - val_accuracy: 0.6202\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 242s 774ms/step - loss: 0.5134 - accuracy: 0.8163 - val_loss: 1.0617 - val_accuracy: 0.6404\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 251s 804ms/step - loss: 0.3589 - accuracy: 0.8779 - val_loss: 1.3221 - val_accuracy: 0.6326\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 248s 793ms/step - loss: 0.2462 - accuracy: 0.9163 - val_loss: 1.4737 - val_accuracy: 0.6209\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 248s 794ms/step - loss: 0.1780 - accuracy: 0.9404 - val_loss: 1.9444 - val_accuracy: 0.6293\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 238s 760ms/step - loss: 0.1245 - accuracy: 0.9593 - val_loss: 2.1136 - val_accuracy: 0.6477\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 236s 753ms/step - loss: 0.1080 - accuracy: 0.9618 - val_loss: 2.3800 - val_accuracy: 0.6163\n"
     ]
    }
   ],
   "source": [
    "History = Modelsimple.fit(X_train_new,dfbalancedsubset.loc[:,'label'],validation_data=(X_test_new,y_test),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "904ef212-ce19-494b-963d-235c8288843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = History.history['val_accuracy']\n",
    "ypred = Modelsimple.predict(X_test_new)\n",
    "ypredmod = np.round(ypred)\n",
    "#Use if label is age or race\n",
    "conmatrix = confusion_matrix(np.argmax(ypred, axis=-1),y_test)\n",
    "#Use if label is gender\n",
    "#conmatrix = confusion_matrix(np.round(ypred),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39e0e086-bacc-43b3-991d-bf5e5e93ceec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5513229966163635, 0.5869870781898499, 0.6234181523323059, 0.6202224493026733, 0.6404193043708801, 0.6326217651367188, 0.6208615899085999, 0.629298210144043, 0.6477054953575134, 0.616259753704071]\n",
      "[[1982  106  125  191  149]\n",
      " [ 295 1129  101  165   95]\n",
      " [ 238   60  771   64   48]\n",
      " [ 362  113   63  760  127]\n",
      " [ 394   96   65  152  172]]\n"
     ]
    }
   ],
   "source": [
    "print(val_accuracy)\n",
    "print(conmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2ae7527-a501-4c76-b193-cd501ae37633",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = filedf.loc[:,'file']\n",
    "dfyage = filedf.loc[:,'gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ebe2a3e-1b10-4644-9fa1-c1785cf378f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dfx, dfyage, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b61d22f-2cbb-4127-90a5-18045dc0e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "yencoded = LabelEncoder().fit_transform(y_train)\n",
    "oversample = RandomOverSampler()\n",
    "X_train_balanced, y_train_balanced = oversample.fit_resample(np.array(X_train).reshape(-1,1), yencoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520d1b41-2066-40b5-93ae-dfdf013810df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=1, n=8307 (50.000%)\n",
      "Class=0, n=8307 (50.000%)\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train_balanced)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_balanced) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67591f72-d0b9-4ba2-a7b8-88ddc4d2b357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16614,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af6ce33e-79f2-4e4c-9294-8c6d916f3c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dxy = {'file': X_train_balanced.reshape(len(X_train_balanced)), 'label': y_train_balanced}\n",
    "dfbalanced = pd.DataFrame(data = dxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7067e355-9db4-4dc8-a75e-3e6d9f2fb3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbalancedsubset = dfbalanced.groupby('label', group_keys=False).apply(lambda x: x.sample(4500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c4c4198-498f-4ae2-9a39-c7e69c4e2cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=4500 (27.086%)\n",
      "Class=1, n=4500 (27.086%)\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(dfbalancedsubset.loc[:,'label'])\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_balanced) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "454b5615-e433-4210-a433-8511cf453258",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_container = []\n",
    "for i in dfbalancedsubset.loc[:,'file']:\n",
    "    img = cv2.imread(i)\n",
    "    train_img_container.append(img)\n",
    "train_img_container = np.array(train_img_container)\n",
    "test_img_container = []\n",
    "for i in X_test:\n",
    "    img = cv2.imread(i)\n",
    "    test_img_container.append(img)\n",
    "test_img_container = np.array(test_img_container)\n",
    "train_img_container = robertsSobelEdges(train_img_container)\n",
    "test_img_container = robertsSobelEdges(test_img_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c705c272-cd7c-4a8b-a1fd-b2cf5aa25d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = tf.expand_dims(train_img_container, axis=-1)\n",
    "X_test_new = tf.expand_dims(test_img_container, axis=-1)\n",
    "Modelsimple=Simplemodel(X_train_new[0].shape,'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c36158-7f6d-4a6b-8956-c44210c18a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "282/282 [==============================] - 224s 794ms/step - loss: 0.5386 - accuracy: 0.7289 - val_loss: 0.5161 - val_accuracy: 0.7682\n",
      "Epoch 2/10\n",
      "282/282 [==============================] - 220s 779ms/step - loss: 0.4200 - accuracy: 0.8078 - val_loss: 0.3867 - val_accuracy: 0.8223\n",
      "Epoch 3/10\n",
      "282/282 [==============================] - 217s 771ms/step - loss: 0.3510 - accuracy: 0.8462 - val_loss: 0.3666 - val_accuracy: 0.8309\n",
      "Epoch 4/10\n",
      "282/282 [==============================] - 198s 702ms/step - loss: 0.2935 - accuracy: 0.8731 - val_loss: 0.3974 - val_accuracy: 0.8265\n",
      "Epoch 5/10\n",
      "282/282 [==============================] - 197s 699ms/step - loss: 0.2446 - accuracy: 0.9024 - val_loss: 0.3645 - val_accuracy: 0.8466\n",
      "Epoch 6/10\n",
      "282/282 [==============================] - 197s 699ms/step - loss: 0.2036 - accuracy: 0.9163 - val_loss: 0.3463 - val_accuracy: 0.8516\n",
      "Epoch 7/10\n",
      "282/282 [==============================] - 197s 700ms/step - loss: 0.1564 - accuracy: 0.9398 - val_loss: 0.4442 - val_accuracy: 0.8506\n",
      "Epoch 8/10\n",
      "282/282 [==============================] - 197s 701ms/step - loss: 0.1215 - accuracy: 0.9538 - val_loss: 0.4407 - val_accuracy: 0.8432\n",
      "Epoch 9/10\n",
      "282/282 [==============================] - 197s 699ms/step - loss: 0.0860 - accuracy: 0.9692 - val_loss: 0.5210 - val_accuracy: 0.8382\n",
      "Epoch 10/10\n",
      "282/282 [==============================] - 204s 723ms/step - loss: 0.0682 - accuracy: 0.9757 - val_loss: 0.5402 - val_accuracy: 0.8460\n"
     ]
    }
   ],
   "source": [
    "History = Modelsimple.fit(X_train_new,dfbalancedsubset.loc[:,'label'],validation_data=(X_test_new,y_test),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02888e89-6e1d-4dfc-8089-e01166391895",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = History.history['val_accuracy']\n",
    "ypred = Modelsimple.predict(X_test_new)\n",
    "conmatrix = confusion_matrix(np.round(ypred),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "309a995e-504b-4020-8487-3a780a40f6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7682474851608276, 0.8223187923431396, 0.830883264541626, 0.8265371322631836, 0.8466061353683472, 0.8515914678573608, 0.8505688309669495, 0.843154788017273, 0.838169515132904, 0.8459669947624207]\n",
      "[[3577  698]\n",
      " [ 507 3041]]\n"
     ]
    }
   ],
   "source": [
    "print(val_accuracy)\n",
    "print(conmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6befaa9d-94d2-47ba-a7ab-3751d892f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = filedf.loc[:,'file']\n",
    "dfyage = filedf.loc[:,'race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ed18320-89de-4a7c-93e4-ec980a1b079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dfx, dfyage, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb0ea01b-3b14-46e9-87f8-42d9dc7090c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yencoded = LabelEncoder().fit_transform(y_train)\n",
    "oversample = RandomOverSampler()\n",
    "X_train_balanced, y_train_balanced = oversample.fit_resample(np.array(X_train).reshape(-1,1), yencoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf3da34b-6019-4c51-98ba-9575f66d4066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=6807 (20.000%)\n",
      "Class=1, n=6807 (20.000%)\n",
      "Class=4, n=6807 (20.000%)\n",
      "Class=2, n=6807 (20.000%)\n",
      "Class=3, n=6807 (20.000%)\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train_balanced)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_balanced) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "922be656-a03b-4ffa-8dee-57a32c8c56a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34035,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d7a9f0a-9cdc-450b-b7f0-65b7738931e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dxy = {'file': X_train_balanced.reshape(len(X_train_balanced)), 'label': y_train_balanced}\n",
    "dfbalanced = pd.DataFrame(data = dxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "213aefa5-fd27-4c5c-b1e7-32ba952f56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbalancedsubset = dfbalanced.groupby('label', group_keys=False).apply(lambda x: x.sample(1800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85c8c348-efa3-4d83-85a3-120122b85f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=1800 (5.289%)\n",
      "Class=1, n=1800 (5.289%)\n",
      "Class=2, n=1800 (5.289%)\n",
      "Class=3, n=1800 (5.289%)\n",
      "Class=4, n=1800 (5.289%)\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(dfbalancedsubset.loc[:,'label'])\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_balanced) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6be43bc1-192a-4d9d-9f52-c64fb2dd192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_container = []\n",
    "for i in dfbalancedsubset.loc[:,'file']:\n",
    "    img = cv2.imread(i)\n",
    "    train_img_container.append(img)\n",
    "train_img_container = np.array(train_img_container)\n",
    "test_img_container = []\n",
    "for i in X_test:\n",
    "    img = cv2.imread(i)\n",
    "    test_img_container.append(img)\n",
    "test_img_container = np.array(test_img_container)\n",
    "train_img_container = robertsSobelEdges(train_img_container)\n",
    "test_img_container = robertsSobelEdges(test_img_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cdadf77-924d-47d5-8eaf-a8b7e9e141b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = tf.expand_dims(train_img_container, axis=-1)\n",
    "X_test_new = tf.expand_dims(test_img_container, axis=-1)\n",
    "Modelsimple=Simplemodel(X_train_new[0].shape,'race')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1f3fe53-b69c-483d-addf-d0a36324e05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "282/282 [==============================] - 195s 690ms/step - loss: 1.5321 - accuracy: 0.2854 - val_loss: 1.3031 - val_accuracy: 0.4748\n",
      "Epoch 2/10\n",
      "282/282 [==============================] - 196s 697ms/step - loss: 1.1582 - accuracy: 0.5413 - val_loss: 1.0962 - val_accuracy: 0.5826\n",
      "Epoch 3/10\n",
      "282/282 [==============================] - 207s 733ms/step - loss: 0.9765 - accuracy: 0.6234 - val_loss: 1.0412 - val_accuracy: 0.6164\n",
      "Epoch 4/10\n",
      "282/282 [==============================] - 219s 777ms/step - loss: 0.8267 - accuracy: 0.6976 - val_loss: 1.0227 - val_accuracy: 0.6073\n",
      "Epoch 5/10\n",
      "282/282 [==============================] - 209s 741ms/step - loss: 0.6628 - accuracy: 0.7664 - val_loss: 1.1000 - val_accuracy: 0.6118\n",
      "Epoch 6/10\n",
      "282/282 [==============================] - 220s 779ms/step - loss: 0.5205 - accuracy: 0.8208 - val_loss: 1.2097 - val_accuracy: 0.5986\n",
      "Epoch 7/10\n",
      "282/282 [==============================] - 209s 740ms/step - loss: 0.3956 - accuracy: 0.8672 - val_loss: 1.5249 - val_accuracy: 0.6032\n",
      "Epoch 8/10\n",
      "282/282 [==============================] - 225s 799ms/step - loss: 0.2883 - accuracy: 0.9017 - val_loss: 1.5787 - val_accuracy: 0.6044\n",
      "Epoch 9/10\n",
      "282/282 [==============================] - 319s 1s/step - loss: 0.2105 - accuracy: 0.9294 - val_loss: 1.5930 - val_accuracy: 0.6169\n",
      "Epoch 10/10\n",
      "282/282 [==============================] - 342s 1s/step - loss: 0.1440 - accuracy: 0.9521 - val_loss: 2.0028 - val_accuracy: 0.5924\n"
     ]
    }
   ],
   "source": [
    "History = Modelsimple.fit(X_train_new,dfbalancedsubset.loc[:,'label'],validation_data=(X_test_new,y_test),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a37b9500-891a-489b-9a88-30b0c449aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = History.history['val_accuracy']\n",
    "ypred = Modelsimple.predict(X_test_new)\n",
    "conmatrix = confusion_matrix(np.argmax(ypred, axis=-1),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efb78989-387d-4edf-9960-d1a5f5642caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4747539162635803, 0.5826409459114075, 0.6163875460624695, 0.6073117852210999, 0.6117857694625854, 0.5986194610595703, 0.6032212972640991, 0.6043717265129089, 0.6168988943099976, 0.5923558473587036]\n",
      "[[1884  141  135  170  141]\n",
      " [ 192  977   69  118   57]\n",
      " [ 223   75  745   57   40]\n",
      " [ 404  172   67  784  110]\n",
      " [ 568  139  109  203  243]]\n"
     ]
    }
   ],
   "source": [
    "print(val_accuracy)\n",
    "print(conmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab909e-c57c-47fb-b5d1-de721c38b081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
