{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8b278f-dc83-49ff-89a5-9cfe2a556c52",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b5c2c-be4b-4277-b1e8-2a66a3ac9529",
   "metadata": {},
   "source": [
    "##### Facial recognition has long remained one of Data Science's most difficult areas to approach. Whereas other types of data have easy to define features and relative simplicity, facial data includes a great deal of hidden or noisy information. Due to this, facial recognition remains a daunting field with no single approach guaranteed to achieve the desired result. And although the human brain excels at instinctively deriving difficult to define features at a glance, programs still struggle to extract something as basic as gender. Yet, should a model be developed that performs as well as humans in all conditions, it would  vastly increase efficiency in all sorts of fields. Basic examples include, medical diagnoses based on facial features, the removal of the need for identification documents, the increased ease of entering one's favorite sites etc. In light of this, the task was to perform exploratory analysis on a number of preprocessing techniques, combined with an analysis of the best performing, and the best performing hyperparameter for said models. Out of four preprocessing techniques (Label Balancing, SIFT,  PCA, RFS) we determined that Label Balancing with oversampling was the best for generalization, while the other techniques lowered training time in exchange for a far greater error rate. Out of four models explored (GBC, CNN, RFS, SVM), GBC and CNN were chosen for similar levels of high accuracy in addition to differing training methods. We then determined the best hyperparameters for each model and visualized how each model functioned at peak performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92bb15c-b0ad-435f-aa75-718f3c92aa66",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd292b33-4723-4367-a556-b5218b80eb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94e83faf-25d3-4264-ad29-9abd02605dbd",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec95d81-c70d-42ca-be3b-ba29099794dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5643b37b-1ae1-451c-ae62-3578780a7c40",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406d025-5d35-4b05-a236-df5e906223a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10b4960e-d64f-4db8-a235-434e89217e31",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf824c9-17b8-4e76-99c3-af4ae3571ccf",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db428b67-d2a2-4ae8-8866-93c9b7552211",
   "metadata": {},
   "source": [
    "### Balance via Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7c49d-b1d6-415e-b6e9-d95be3537303",
   "metadata": {},
   "source": [
    "### SIFT - (Scale Invariant Feature Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ef4ba-7018-4b24-a721-0fed720d6280",
   "metadata": {},
   "source": [
    "##### A technique for simplifying the complexity of an image by transforming it into a histogram of commonly found features. The features within an image are defined as keypoints within the SIFT algorithm. A key point is defined as a local extrema within an image that is found by comparing a pixel with its neighbors for drastic shifts in pixel values. Next, a descriptor is taken of the local area around each key point which consists of a 128 bin feature vector. This vector describes the local area and a direction, allowing the keypoint to be applicable despite rotation. 128 bin descriptors are collected from training images and clustered via K-means to produce common descriptors. Then each image can be transformed into a histogram with each bin representing the number of times a common feature was detected within the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5581b0b6-2fee-402c-a391-9e601a578730",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd42a83-89da-4961-9135-b18924c323e0",
   "metadata": {},
   "source": [
    "### RFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a5888-20b0-4fd0-8e78-f9773171a567",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e96c4-45ca-4b28-a48e-02a42d6de817",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedc8945-67ff-4af1-ab9d-fcf80866fe9f",
   "metadata": {},
   "source": [
    "##### Each neural network was run with a maximum of 10 epochs with the optimizer adam and sparse categorical cross entropy loss. A callback was implemented with a patience of 5 and monitored the validation accuracy. This was so that the model would return the weights for the best validation accuracy should the model run for 5 epochs without improvement. Testing will be done on the age variable due to it having the most unbalanced and varied classes.\n",
    "##### Metrics used will be base accuracy, macro f1-score, macro recall, and macro-precision. This is so that we may compare how the model is doing on the entire validation dataset as well as whether it has equal metrics across all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921e537-ea9b-4111-a241-58bb0db76f21",
   "metadata": {},
   "source": [
    "#### Preprocessing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c748d-51bb-4b60-a024-10bb19c51cf3",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"200\">\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/PreProcessingResults.PNG\"/>\n",
    "            <figcaption>Fig.14 Results matrix for preprocessing on validation</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba4d500-5604-42e9-9536-f138cac6fc7d",
   "metadata": {},
   "source": [
    "#### Balanced versus Unbalanced\n",
    "##### While the unbalanced dataset had greater accuracy than the balanced dataset, the balanced dataset had superior macro precision, recall, and f1-score. Balanced datasets would be chosen from then on.\n",
    "#### Normalized versus Raw data\n",
    "##### The normalized dataset had worse results in addition to requiring additional memory to store float64 values instead of int8. Raw data should be chosen from then on.\n",
    "#### Balanced versus RFS, PCA, SIFT\n",
    "##### All metrics resulting from the preprocessing techniques were worse than corresponding metrics in the non preprocessed balanced dataset. Thus, no preprocessing techniques would be utilized.\n",
    "#### Verdict:\n",
    "##### The non-normalized, balanced, non-preprocessed dataset has the best performance out of all iterations with an accuracy of 0.42."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec6d9ba-da2a-4a82-9af0-0846e705c377",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f5569-6986-4186-9489-3e2974c5c16c",
   "metadata": {},
   "source": [
    "##### Based on initial results, GBC was to be chosen for its high level of accuracy. However, a better Neural Network Structure was discovered which gave an accuracy of 0.48. This is 0.02 above the GBC accuracy of 0.46. Thus, Neural Networks will be utilized for hyperparameter tuning. The selected structure is listed below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2318072-83c4-40b9-9406-bf87d58e309b",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ModelSummary.PNG\"/>\n",
    "            <figcaption>Fig.x Neural Network Structure</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c1855-2a5f-4cf5-b58c-391f32cb6963",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0f85b4-2840-4d79-8804-42d6e3bdd88b",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b19a5b-11f8-466d-889e-0ed64be91070",
   "metadata": {},
   "source": [
    "##### After concluding that a balanced dataset yielded the best performance and that the model itself was the 2nd most accurate, further hyperparameter tuning was needed to achieve a global maximum of performance. Five hyperparameters were tuned for the following runs: Dropout, L1 Regularization, L2 Regularization, Learning Rate, and Number of samples. A hyperparameter would only be considered if its accuracy was greater than the base model by more than 0.01. This threshold is to ensure that improvements are not due to changes in samplinga and are instead because the model genuinely improved.\n",
    "#### Base Model's Hyperparameters\n",
    "##### - Dropout: 0\n",
    "##### - L1: 0\n",
    "##### - L2: 0\n",
    "##### - Lr: 0.001\n",
    "##### - Sampling Size: 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d8fdd-40ee-4ff4-9341-308396ed426e",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a776a856-530f-4d7e-99c5-ed53b5a7e157",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/L2Report.PNG\"/>\n",
    "            <figcaption>Fig.15 L2 hyperparameter tuning values</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/L1Report.PNG\" />\n",
    "            <figcaption>Fig.16 L1 hyperparameter tuning values</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/DropoutReport.PNG\" />\n",
    "            <figcaption>Fig.17 Dropout hyperparameter tuning values</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/LrReport.PNG\" />\n",
    "            <figcaption>Fig.18 Learning Rate hyperparameter tuning values</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c173d55-6c09-4b9d-a511-fc45b9982efc",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Based on hyperparameter tuning on all models, L1: 0.001 and Lr: 0.0001 were the best candidates since their accuracy was beyond 0.01 of the base accuracy of 0.485552."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de283cd5-625e-4299-9f5c-5d95cf8ef344",
   "metadata": {},
   "source": [
    "### Sample Size Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae34cb2-d236-4dec-b7c8-9fefe0ddff5c",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/SampleAcc.PNG\"/>\n",
    "            <figcaption>Fig.27 Sample Size hyperparameter tuning versus accuracy</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/SampleLoss.PNG\" />\n",
    "            <figcaption>Fig.28 Sample Size hyperparameter tuning versus loss</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7034d4b3-ecf3-4f8e-aafe-c01e4e41fc1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Sample size amounts were tested from 500 to 8000 in intervals of 500. It was found that 5000 had the highest accuracy. Like before, the model loss seems to inversely correlate with the model's accuracy. Although the model was most accurate on 5000 samples, we will be using the 8000 as using more data is best practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d02c06-5e96-4710-8142-152ff0b445ac",
   "metadata": {},
   "source": [
    "### Post Hyperparameter testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a767e205-f7bd-4338-9007-f015be78043e",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/8000TestRaceReport.PNG\"/>\n",
    "            <figcaption>Fig.30 Classification report for the race test set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/8000TestReport.PNG\" />\n",
    "            <figcaption>Fig.31 Classification report on the age test set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/8000TestGenderReport.PNG\" />\n",
    "            <figcaption>Fig.32 Classification report on the gender test set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ede95-34dd-444a-90ea-990d438c38b3",
   "metadata": {},
   "source": [
    "##### After some basic runs, it was discovered that LR: 0.0001 had the best validation accuracy at 0.61 and a test accuracy of 0.62. The classification report on age shows far better results than that of the control model. In addition, the race and gender model using the same neural network structure achieved better results than the dummy models. Thus, this model was to be considered satisfactory. The only thing left to do was to visualize the weakpoints of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa66b3c-aa68-4c40-b693-58be30b0c715",
   "metadata": {},
   "source": [
    "### Feature extraction by analyzing mislabeled classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5439e33-5a7a-489a-9170-17e1bd8ba686",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09536c6-9af4-4dcd-b671-098eba33adb6",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/C15.PNG\"/>\n",
    "            <figcaption>Age Bracket: 5</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/C21.PNG\" />\n",
    "            <figcaption>Age Bracket: 1</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/C38.PNG\" />\n",
    "            <figcaption>Age Bracket: 8</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/IC14.PNG\"/>\n",
    "            <figcaption>Correct Label: 4 Predicted Label: 5</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/IC20.PNG\" />\n",
    "            <figcaption>Correct Label: 0 Predicted Label: 1</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/IC35.PNG\" />\n",
    "            <figcaption>Correct Label: 5  Predicted Label: 8</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9cdca-3915-469b-b287-50d4fa740c7d",
   "metadata": {},
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6639b8-9b66-4972-a9f4-07e16ad9b1f5",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/C13.PNG\"/>\n",
    "            <figcaption>Race: Indian</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/C22.PNG\" />\n",
    "            <figcaption>Race: Asian</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/C31.PNG\" />\n",
    "            <figcaption>Race: Black</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/IC10.PNG\"/>\n",
    "            <figcaption>Correct Label: White Predicted Label: Indian</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/IC24.PNG\" />\n",
    "            <figcaption>Correct Label: Other(All other races in this category) Predicted Label: Asian</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/IC33.PNG\" />\n",
    "            <figcaption>Correct Label: Indian  Predicted Label: Black</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eaa10d-b877-4f90-b15b-b5b05e37c10b",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765ef04-424b-4e10-b41a-3a40cb782ce9",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Gender/C11.PNG\"/>\n",
    "            <figcaption>Gender: Female</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Gender/C20.PNG\" />\n",
    "            <figcaption>Gender: Male</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Gender/IC10.PNG\"/>\n",
    "            <figcaption>Correct Label: Male Predicted Label: Female</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Gender/IC21.PNG\" />\n",
    "            <figcaption>Correct Label: Female Predicted Label: Male</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36eebb5-11b1-4b7c-a0d8-3ff4023dd9ab",
   "metadata": {},
   "source": [
    "#### Features extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ad1fef-1d89-4d65-bbaa-e7602980ff33",
   "metadata": {},
   "source": [
    "##### How the model performs feature extraction can be analyzed by comparing the misclassifications. \n",
    "##### On the age model, it tends to use features associated with the facial edges or facial shape. This is evidenced by the similarity of wrinkles on the third pair, the smoothness of face on the first pair, and the round facial shape of the second pair.\n",
    "##### On the race model, it mostly seems to use facial shape when determining racial features. Interestingly enough, skin color does not seem to be a factor in determining race for the model.\n",
    "##### On the gender model, it is difficult to tell what the model is using to determine gender. The second pair disproves that the model is using facial shape as the main feature. In addition, both image pairs have different tones and different winkle edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad3443-35ce-4486-96e9-ac54bd45caf2",
   "metadata": {},
   "source": [
    "### Final Comparison between Neural Networks, Dummy Model, Simple Models, and Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53a532-2a6d-47c2-898b-19ec3156cdf8",
   "metadata": {},
   "source": [
    "##### Based on the age metric, the hyperparameter tuned neural network with Lr: 0.0001 outperforms all other models. The final age accuracy for the neural network was 0.62. If we compare to the simple models, KNN has a testing accuracy of 0.27 and Logistic Regression has a testing accuracy of 0.46. When we compare to the dummy model, it has an accuracy of 0.14."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3450dfaa-d9c4-44f2-8398-bb6bbcc54c0b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc085b46-5c47-4be0-80bc-c1f7c59c3e12",
   "metadata": {},
   "source": [
    "##### In all metrics, the Neural Network with hypertuning outperformed all other models. There was enough data to train each model on. However, the lack of memory within the testing machine limited the images trained to 5000 instead of potentially 60000 images in the fully balanced dataset. Based on the image misclassifications, the model seems to mainly use facial shapes, wrinkles, and smoothness as features. If there is any future work to be done, it would be to find a way to simplify the dataset to train more samples while retaining most of the information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56a646-0ef1-4041-bb90-66d86613f4f4",
   "metadata": {},
   "source": [
    "# Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a52976-b9a6-4cc8-8f0f-2be3f9724d08",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/GitCommitsandlines.PNG\"/>\n",
    "            <figcaption>Commits/additions/deletions per person</figcaption>\n",
    "        </figure>\n",
    "</tr>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "    ofirsov000 : Oxana Firsova\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "    jvivar2383 : Jenifer Vivar\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "    usersblock : Thomas Ly\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "    yxiang001 : Yinzi Xiang\n",
    "    </td>\n",
    "</tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b79da-eb55-4ee4-bd1f-c5d803677816",
   "metadata": {},
   "source": [
    "#### Oxana Firsova"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4d8df-6413-45be-869e-475cf4216d10",
   "metadata": {},
   "source": [
    "##### Balanced all labels by applying SMOTE Technique. Splitting age label into 9 stages based on the Human Life Cycle.  Implement SVM algorithm. Applied masks on SVM and test accuracy score. Compare the accuracy on SVM with Sift and without. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a4a50-57c3-4130-8a6f-0d78f7443a09",
   "metadata": {},
   "source": [
    "#### Jenifer Vivar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada2decf-bb99-4faa-943c-03ceb313ef55",
   "metadata": {},
   "source": [
    "##### Added pre-processing techniques like Hair Cascade and several images filters (later discarded) for apply to the images before using them for the classier. I also, implemented a Random Forest algorithm and test the accuracy scores on the process and preprocess data to later compared with other models my group members were working on. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251a7149-a511-481f-8ae3-5a0397b68772",
   "metadata": {},
   "source": [
    "#### Thomas Ly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f0c24-8082-4c31-ab36-15afcb444b1d",
   "metadata": {},
   "source": [
    "##### Implemented the SIFT slgorithm to extract image features and simplify dimensions. Implemented the Convolutional Neural Network and preprocessed the dataset to find the best dataset for Neural Network. Hyperparameter tuned the Neural Network and performed feature extraction on the images based on misclassified examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68223b9-2c3f-4415-b123-f22eeab62633",
   "metadata": {},
   "source": [
    "#### Yinzi Xiang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74426497-c574-4599-94de-a2d2d19edb2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Explore the feature extraction PCA and feature selection Random Forest feature selection. Explore, set and study the model of Gradient Boosting Classifier. Applied this model with feature extraction like PCA, shift and RFS under balanced and unbalanced labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc89917-1a55-414d-961f-9b0cf365f88a",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb54d4-d684-437b-b17d-5f5da5249f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c029bf-33fa-4643-8a92-a7e73c528f5f",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2490961-3d9a-40a7-a5cb-a2d913372784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
