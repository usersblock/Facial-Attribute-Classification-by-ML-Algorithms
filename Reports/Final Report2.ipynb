{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aadd1796-7d88-42af-a037-b63b5746af96",
   "metadata": {},
   "source": [
    "# Race, Age, and Gender Classifcation Improvement Using Feature Engineering on Images\n",
    "<figure>\n",
    "<center>\n",
    "<img src = \"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/images/Screen%20Shot%202022-05-22%20at%204.25.31%20PM.png\" width = 300 height = 300 >\n",
    "<br>\n",
    "    \n",
    "<caption> Image of Faces</caption>\n",
    "</center>\n",
    " <figure>\n",
    "     <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b278f-dc83-49ff-89a5-9cfe2a556c52",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b5c2c-be4b-4277-b1e8-2a66a3ac9529",
   "metadata": {},
   "source": [
    "Facial recognition has long remained one of Data Science's most difficult areas to approach. Whereas other types of data have easy to define features and relative simplicity, facial data includes a great deal of hidden or noisy information. Due to this, facial recognition remains a daunting field with no single approach guaranteed to achieve the desired result. And although the human brain excels at instinctively deriving difficult to define features at a glance, programs still struggle to extract something as basic as gender. Yet, should a model be developed that performs as well as humans in all conditions, it would  vastly increase efficiency in all sorts of fields. Basic examples include, medical diagnoses based on facial features, the removal of the need for identification documents, the increased ease of entering one's favorite sites etc. In light of this, the task was to perform exploratory analysis on a number of preprocessing techniques, combined with an analysis of the best performing, and the best performing hyperparameter for said models. Out of four preprocessing techniques (Label Balancing, SIFT,  PCA, RFS) we determined that Label Balancing with oversampling was the best for generalization, while the other techniques lowered training time in exchange for a far greater error rate. Out of four models explored (GBC, CNN, RFS, SVM), GBC and CNN were chosen for similar levels of high accuracy in addition to differing training methods. We then determined the best hyperparameters for each model and visualized how each model functioned at peak performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92bb15c-b0ad-435f-aa75-718f3c92aa66",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a05773-df76-4afd-98f0-c3479c343e48",
   "metadata": {},
   "source": [
    "Image classification techniques are widely apply in the machine learning community and well understood by many. Today's world rely more and more on advance features to protect our identities online and to protect many sensitive information such as SSN and banck accounts. While basic features, such as eye color, nose, etc. are easiily recognisable to the models there are many others that remain still abstract and not easily identified by the algorithms. Some of this features include age, gender and race.Many models attempt to solve this problems but the criteria and actual performance are still inadequate. Adding these features to the basic features could potencially increase the level of security in face recognision applications. The combinations of unique physical features combined with other variables like age, gender and race could add an extra layer of security protection to any application that needs extreme security for sensible online transaction and for our right to privacy while online.\n",
    "<br>\n",
    "<br>\n",
    "Based on previous work done on the field it is clear that there is no one way to solve this problem. There is a diversity of algorithms apply to solve this problem as well as a diversity of benchmarks to asses test performace. In this project the focus was on two particular models, Gradient Boosting and Neural Networks. Moreover, an emphasis was applied to data engineering and various pre-processing techniques.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e83faf-25d3-4264-ad29-9abd02605dbd",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec95d81-c70d-42ca-be3b-ba29099794dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5643b37b-1ae1-451c-ae62-3578780a7c40",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f89905-f82a-4181-b353-7750ea736896",
   "metadata": {},
   "source": [
    "The Dataset was taken from Kaggle and could be uploaded in this link. The Faces dataset contains 20000+ cropped & aligned facial images with age, race and gender labels. Age label modified to 9 stages based on The Stages  of Human Life Cycle. Project has 6000 testing examples 3500 validation and 10500 training. After balancing training examples, we took 5000 samples proportionally. The pixel values are integer between 0 and 255. To normalize data, we divide it by 255. Each image has a shape of (200,200,3). Features were extracted by PCA.\n",
    "\n",
    "The UTKFACE data set consist of 20000 labeled images. The images's labels consist of the target variables of age, gender and race. The age in the set ranges from 0-116 years old. The gender is 0 for make and 1 for female, and race from 0-4.\n",
    "<ul>\n",
    "    <li>[age] is an integer from 0 to 116, indicating the age</li>\n",
    "    <li>[gender] is either 0 (male) or 1 (female)</li>\n",
    "<li>[race] is an integer from 0 to 4, denoting White, Black, Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern).</li>\n",
    " </ul>\n",
    " \n",
    "The data set consits of mainly two categories, \"in the wild image set\" which are pictures of people with different backgrounds and settings and \"cropped images\" which are images were the face of each person was cropped to exclued as much of the bacground as possible. In this project the latter was used to train and test the models.\n",
    "\n",
    "[ADD IMAGE INBALANCE]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0221859-af98-4b85-a209-827d5c994881",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/images/PCA.png\"/>\n",
    "            <figcaption>Fig.19 PCA Feature Extraction</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b4960e-d64f-4db8-a235-434e89217e31",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72652f6-571b-4090-9508-ff2259bdb2f4",
   "metadata": {},
   "source": [
    "<center><h3>Unbalanced Dataset</h3></center>\n",
    "Data balancing was one of themost importants taks we had to do before doing any other pre-processing work. Many of the labels were highly unbalances\n",
    "\n",
    "<center><h3>SIFT</h3></center>\n",
    "A technique for simplifying the complexity of an image by transforming it into a histogram of commonly found features. The features within an image are defined as keypoints within the SIFT algorithm. A key point is defined as a local extrema within an image that is found by comparing a pixel with its neighbors for drastic shifts in pixel values. Next, a descriptor is taken of the local area around each key point which consists of a 128 bin feature vector. This vector describes the local area and a direction, allowing the keypoint to be applicable despite rotation. 128 bin descriptors are collected from training images and clustered via K-means to produce common descriptors. Then each image can be transformed into a histogram with each bin representing the number of times a common feature was detected within the image.\n",
    "\n",
    "One of the techniques used in this project was SIFT, which stands for Scale Invariant Feature Transform. Th reason for using this algorithm to our images is because SIFT's ability to detect major key points in an image. This is particularly useful for the three features we're focusing on in this project (age, gender, and age). The SIFT program is particularly useful because the quality of the images and angle of them have a known low inpact on the prediction of key features in the images. The algorithm was implemented as benchmark results anaylsis as it one of the most use algorithms use for facial recognition.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/Reports/figures/Screen%20Shot%202022-05-24%20at%202.02.26%20PM.png\" width = \"200\" height = \"200\">\n",
    "    <br>\n",
    "<caption> SIFT Facial Attributes Recognition</caption>\n",
    "</center>\n",
    "[ADD MORE ABOUT SIFT?]\n",
    "\n",
    "\n",
    "<center><h3>Haar Cascade</h3></center>\n",
    "Haar Cascade is an object detection algorithm. The algorithm selected important features from the images and bounds them into squares. The number of features scalate very quickly. Because of the high number of features created with theis program the Adaboost algorithm is used to select only the most important features. Adaboost does this by using a collection of weak classifers to create a strong classifier. In this project the Haar Cascade algorithm was trained with the haar cascade collection of face recognition images in their library. The goal of using Haar Cascade was to find the bounds of the faces in the images and zero out all of the pixels outside of the face boundary. This was done with the goal of maximizing the features pass onto each model and reducing surrounding noise and objects.\n",
    "<center>\n",
    "<img src = \"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/jen_branch/images/Haar_Cascade_image.png\" width = 300 height = \"300\">\n",
    "    <br>\n",
    "<caption> Haar Cascade Object Recognition</caption>\n",
    "</center>\n",
    "\n",
    "<center><h3>PCA</h3></center>\n",
    "Speed is also a primary concern in this project. For this reason selecting only the relevant features of each image was important for the project. The images used for the classification each had the shape (200, 200, 3). In order to reduce the features the rgb portion needed to be removed leaving a 2D matric of an imaged of (200, 200). Once the images was flatten the matrix became an array with 40000 values. After applying the PCA algorithms it was determined that if 196 features were kept, above of 90% of the variance could be preserved. This feature reduction technique was apply to every image to speed the classification process.\n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/images/PCA.png\"/>\n",
    "            <figcaption>Fig.19 PCA Feature Extraction</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    \n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<center><h3>Random Forest Feature Selection</h3></center>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf824c9-17b8-4e76-99c3-af4ae3571ccf",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db428b67-d2a2-4ae8-8866-93c9b7552211",
   "metadata": {},
   "source": [
    "### Balance via Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7c49d-b1d6-415e-b6e9-d95be3537303",
   "metadata": {},
   "source": [
    "### SIFT - (Scale Invariant Feature Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ef4ba-7018-4b24-a721-0fed720d6280",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5581b0b6-2fee-402c-a391-9e601a578730",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd42a83-89da-4961-9135-b18924c323e0",
   "metadata": {},
   "source": [
    "### RFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b176bd-0be6-4867-8464-39966dd0ac2d",
   "metadata": {},
   "source": [
    "##### Random Forest Feature Selection (RFS) is selecting the features based on the Random Forests machine learning algorithms’ fitted attribute feature_importances_. It is straightforward and easy to compute how much each variable is contributing to the decision. The feature importance is computed as the mean and standard deviation of accumulation of the impurity decrease within each tree. We grayscale the UTK face image dataset and fitted the grayscale dataset to the Random forest model. Then we pick the important features through Random Forest fitted attribute feature_importances_ for our image pixels dataset. After that, we trained our model with all those important features to see if there are any improvements in the model performance. The grayscale UTK face image dataset has 200*200 pixel features on it. After applied the Random Forest Feature Selection on the grayscale dataset. We got 12794 features. This way reduce a lot noise feature for our models.\n",
    "\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/images/Feature number before after RFS.png\"/>\n",
    "            <figcaption>Fig. Feature number before after RFS</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/images/Image for after RFS.png\"/>\n",
    "            <figcaption>Fig. Image for after RFS.png</figcaption>\n",
    "        </figure>\n",
    "    </td>    \n",
    "    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d0d7b4-5733-4d91-b788-380f7a3fecc0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f6a7df-324e-4fb0-8b3a-96c724d71ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "313a5888-20b0-4fd0-8e78-f9773171a567",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e96c4-45ca-4b28-a48e-02a42d6de817",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedc8945-67ff-4af1-ab9d-fcf80866fe9f",
   "metadata": {},
   "source": [
    "##### Each neural network was run with a maximum of 10 epochs with the optimizer adam and sparse categorical cross entropy loss. A callback was implemented with a patience of 5 and monitored the validation accuracy. This was so that the model would return the weights for the best validation accuracy should the model run for 5 epochs without improvement. Testing will be done on the age variable due to it having the most unbalanced and varied classes.\n",
    "##### Metrics used will be base accuracy, macro f1-score, macro recall, and macro-precision. This is so that we may compare how the model is doing on the entire validation dataset as well as whether it has equal metrics across all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f6b32-7152-4d81-b58c-e9493f27c49a",
   "metadata": {},
   "source": [
    "#### Unbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa572c2-330b-4b33-be39-0d28c67bcf9a",
   "metadata": {},
   "source": [
    "##### Although not recommended, the effects of an unbalanced dataset towards a model should be investigated. The effects of the raw dataset upon various metrics are illustrated in the figures below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c574a05-3962-40c9-8b4c-c9c716fcd88e",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/UnbalancedModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.1 Classification report for the validation set on age</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/UnbalancedModel/ConMatValAge.PNG\" width=\"400\" />\n",
    "            <figcaption>Fig.2 Classification Matrix on the validation set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/UnbalancedModel/ModelAcc.PNG\" width=\"400\" />\n",
    "            <figcaption>Fig.3 Model Accuracy per Epoch</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ccbae9-3304-41d4-a186-1ef0d9bd6614",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### For figure 1 accuracy of 0.56 better than all other models. However, note the f1 scores for classes 1,2, 3 compared to the f1 scores for class 0, 5, 6, 7. Classes 1, 2, 3 were the least frequent labels, while classes 0, 5, 6, 7 were far more common. Since the least common classes have no predictions whatsoever, we can conclude that the model did not receive enough training labels for those classes. Another important metric to consider is the macro avg, which is the average accuracy across all classes if weighted the same. This will be compared to the next model which will have balanced classes.\n",
    "##### Figure 2 further illustrates the issues presented in the classification report. The matrix clearly shows how most predictions by percentage were clustered around the most common labels.\n",
    "##### Figure 3 can be considered deceptive if one did not check the classification report. Although it displays high accuracy compared to later dummy models, it shows total accuracy which favors the larger classes by default.  {DO AGAIN}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f310550f-c4a9-4086-a554-ebfba2cae684",
   "metadata": {},
   "source": [
    "#### Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3488e829-877d-412d-88f5-4f99386d64cd",
   "metadata": {},
   "source": [
    "##### This dataset was created via the oversampling of unbalanced class labels until they reached the quantity of the most frequent class. Then, a balanced sampling of 5000 was taken from these labels. The results of the model training are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d755d6b5-a6b7-4ef0-b21d-16893f87ac17",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/BalancedModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.4 Classification report for the validation balanced set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/BalancedModel/CLMatrixVal.PNG\" />\n",
    "            <figcaption>Fig.5 Classification Matrix on the validation balanced set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/BalancedModel/AccPlot.PNG\" />\n",
    "            <figcaption>Fig.6 Model Accuracy per Epoch</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002f2e5-0dae-4566-b8e1-636080cd7c16",
   "metadata": {},
   "source": [
    "##### Analyzing figure 4, the accuracy is far lower than the unbalanced dataset. However, the macro average is far higher compared to the unbalanced model. In addition, the least common labels are being predicted to a far greater extent than the unbalanced model. While the most common labels have a lower accuracy, this is only because the model isn't blindly predicting the most common labels to be correct.\n",
    "##### As for figure 5, the prediction distribution is far more balanced compared the the unbalanced dataset. This is important as the model is meant to predict all labels well, not just one. \n",
    "##### Figure 6 displays the main issue that preprocessing and hyperparameter tuning will attempt to address. Due to limited memory, only 5000 samples may be trained at maximum. Naturally, this has caused great levels of overfitting in the attempt to classify (200,200,3) images. In addition, it also shows the model overfitting within the first half and plateauing afterwards.\n",
    "##### Overall, using a balanced dataset is necessary for generalization and later runs will attempt to address overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225564bf-14d0-4c9c-b77f-7c6bbf48fdaf",
   "metadata": {},
   "source": [
    "#### Normalized Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b50db04-379f-411d-a62a-2a9b1ce54941",
   "metadata": {},
   "source": [
    "##### Each image was normalized in accordance to its highest and lowest pixel values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b9c77-bc55-49e8-827b-bdc0e3b98252",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/NormalizedModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.7 Classification report for the validation normalized set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/NormalizedModel/AccPlot.PNG\" width=\"400\" />\n",
    "            <figcaption>Fig.8 Classification Matrix on the validation normalized set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12425c16-d8b8-4b92-a72f-9d046f713934",
   "metadata": {},
   "source": [
    "##### In figure 7, compared to the control balanced dataset, the normalized dataset is 0.03 less accurate. In addition, the macro accuracy is 0.05 less accurate than the non-normalized dataset on the f1-score. With this, it can be concluded that a non-normalized dataset should be used for the rest of the techniques. What should be noted is that in figure 8, the model has reached maximum accuracy in later epochs, meaning this dataset takes longer to overfit.\n",
    "##### Despite this, the normalized dataset's overall performance has indicated that is it a poor preprocessing technique for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa75753-7c0c-47f1-88c1-01acea16a274",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a913e8a-5be8-417a-bc71-25a7ba203709",
   "metadata": {},
   "source": [
    "##### For the PCA dataset, the image arrays were first flattened into the shape of (1,120000). When running the training images through the PCA dimension reduction technique, PCA was initialized to only keep enough components to reach a minimum of 0.90 explained variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c486ca-dcf0-4172-b31e-a19dc6614a42",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/PCAModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.9 Classification report for the validation PCA set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/PCAModel/ValMatrix.PNG\" />\n",
    "            <figcaption>Fig.10 Classification Matrix on the validation balanced set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f507cf3-bd0a-4cef-b136-8bf389e3775f",
   "metadata": {},
   "source": [
    "##### Based on the accuracy and macro averages on figure 9, it is clear that the PCA dataset performs poorly compared to the balanced dataset. This is despite the fact that 0.90 explained variance was present within the dataset.\n",
    "##### The reasoning becomes clearer when looking at figure 10. However PCA affected the dataset, it has resulted in the model predicting mostly on label 5, the most common one. Thus, PCA should not be included in Neural Network's preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f60523-af15-4194-ad50-12a61f51a7e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### RFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dcb479-81c9-46e8-8d59-0ceb651ae67c",
   "metadata": {},
   "source": [
    "##### Random Forest Selection is an ensemble method used for feature selection. It does so by utilizing a number of Decision trees and calculating how much each feature decreases the impurity. From all the trees, it can determine the importance of a feature. Lastly, RFS returns the features that have a greater importance than the mean importance. Out of 120,000 pixel features, RFS chose 36,407 features. This is nearly 1/4th of the original dataset's complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe711e9a-0dc9-4afd-a4c4-c9474994b112",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/RFSModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.11 Classification report for the validation RFS set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/RFSModel/LossPlot.PNG\" />\n",
    "            <figcaption>Fig.12 Loss plot for validation RFS set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ec8efe-ed35-4458-bd29-07ad2cd0e072",
   "metadata": {},
   "source": [
    "##### Compared to the balanced model, RFS achieves slightly worse results. The accuracy differs by -0.03 and the macro average differs by -0.02 for the f1 score. While RFS won't be used for hyperparameter tuning for the sake of higher accuracy, it can serve as a reliable and small dataset.\n",
    "##### According to figure 12, the model learns quickly as evidenced by the training line. While the line does plateau by epoch 10, the model achieves near perfect accuracy by the end. However, the validation line suggests that the model does overfit early like the other models. Thus, it is unlikely that this solves the overfitting issues present in the control balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5a0ab-1348-4477-b182-f26df34e6420",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### SIFT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5abdd-0ab3-49ca-9910-502b19430ab4",
   "metadata": {},
   "source": [
    "##### SIFT is a form of feature selection which simplifies images into histograms of commonly found image feaures. It does so by finding common image descriptors in the training set and utilizing the common descriptors to transform all images into histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e94a6c-e9a4-4d56-9d63-671bebe7ee8e",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/SIFTModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.13 Classification report for the validation SIFT set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/SIFTModel/ValMatrix.PNG\" />\n",
    "            <figcaption>Fig.14 Classification Matrix on the validation SIFT set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da14a34-e78a-4966-8780-30163301006c",
   "metadata": {},
   "source": [
    "##### The accuracy and macro f1-score was far lower than the balanced dataset. This suggests that while SIFT did transform the data, it did not keep enough relevant information for the training model to successfully generalize. This is further evidenced by the fact that it has a distributed accuracy, but low accuracy overall. Thus, we will not be using SIFT despite its fast training speed.\n",
    "##### One thing to note from figure 14, is its similarity to the classification matrix on the PCA dataset. From this, it seems that drastically reducing an image's dimensions can cause the model to misclassify most images in favor of the most common classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921e537-ea9b-4111-a241-58bb0db76f21",
   "metadata": {},
   "source": [
    "#### Preprocessing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c748d-51bb-4b60-a024-10bb19c51cf3",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/PreProcessingResults.PNG\"/>\n",
    "            <figcaption>Fig.14 Results matrix for preprocessing on validation</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba4d500-5604-42e9-9536-f138cac6fc7d",
   "metadata": {},
   "source": [
    "#### Balanced versus Unbalanced\n",
    "##### While the unbalanced dataset had greater accuracy than the balanced dataset, the balanced dataset had superior macro precision, recall, and f1-score. Balanced datasets would be chosen from then on.\n",
    "#### Normalized versus Raw data\n",
    "##### The normalized dataset had worse results in addition to requiring additional memory to store float64 values instead of int8. Raw data should be chosen from then on.\n",
    "#### Balanced versus RFS, PCA, SIFT\n",
    "##### All metrics resulting from the preprocessing techniques were worse than corresponding metrics in the non preprocessed balanced dataset. Thus, no preprocessing techniques would be utilized.\n",
    "#### Verdict:\n",
    "##### The non-normalized, balanced, non-preprocessed dataset has the best performance out of all iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c1855-2a5f-4cf5-b58c-391f32cb6963",
   "metadata": {},
   "source": [
    "<center><h2>Evaluation </h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fc1fd0-f966-4ef6-9fea-a93a745ecbb0",
   "metadata": {},
   "source": [
    "<h3>Dummy Model Comparison</h3>\n",
    "For this project several methods wwere apply to test the accuracy of the model. One important component that many computer scientist miss is that of comparing their model with a random guessing algorithm. The dummy functions develop attemp to answer, is the model really claasifiying methods correctly and are the predictions better than random guessing alone. In figure x is observed the low accuracy value of 14%. Compare to both our models this percentage is low and tell us that our models are indeed doing better than random guessing. The model was implemented by following teh balanced labels on age, using a random generator object, and adding more weigh to the labels that were repeated the most in the data. The labels are coded from 1-9 as follows:\n",
    "<ol>\n",
    "    <li> infancy (0-2)</li>\n",
    "    <li>Early Childhood (Ages 3-5)</li>\n",
    "    <li>Middle Childhood (Ages 6-8)</li>\n",
    "    <li>Late Childhood (Ages 9-11)</li>\n",
    "    <li> Adolescence (Ages 12-20)</li>\n",
    "    <li> Early Adulthood (Ages 21-35)</li>\n",
    "    <li> Midlife (Ages 36-50)</li>\n",
    "    <li> Mature Adulthood (Ages 51-79)</li>\n",
    "    <li> Late Adulthood (Age 80+)</li>\n",
    "</ol>\n",
    "\n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/images/Screen%20Shot%202022-05-25%20at%201.56.26%20PM.png\" height =\"200\" width = \"200\" >\n",
    "            <figcaption>Fig. x showing the classification report on random guessing of age labels</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>\n",
    "Similarly to age a dummy model was also made to random guess the race labels. On this instace the values were from 0 to 4. As before, weigh was added to the values according to frecuency in the data set. Observed the low accuracy score of 0.08 or 8%. This is a good indication that our models are better than random guessing\n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/images/Screen%20Shot%202022-05-25%20at%201.55.59%20PM.png\" height =\"200\" width = \"200\" >\n",
    "            <figcaption>Fig. x showing the classification report on random guessing of race labels</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>\n",
    "Lastly, for the gender labels. Because there are two values, 0 for male and 1 for female, a simple binary random number generator was created to simulate random predictions. As expected the accuracy in the report of the figure below is ~50%. The classfication models are doing better than just random guessing and that is a good point to validate all the work this project encompas. \n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/images/Screen%20Shot%202022-05-25%20at%201.55.36%20PM.png\" height =\"200\" width = \"200\" >\n",
    "            <figcaption>Fig. x showing the classification report on random guessing of gender labels</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3322f1ad-e686-4809-9de6-9f425f63f98e",
   "metadata": {},
   "source": [
    "#### Logistic Regression and KNN\n",
    "Logistic regression is the most important and useful sample model. Unlike linear regression, logistic regression can directly predict values that are limited by an interval (0.1), such as probabilities. This method for predicting probabilities or coefficients, and like linear regression, can be thought of as guidelines. It is also a good first choice for binary classification problems.\n",
    "We developed 2 simple models KNN and Logistic Regression. As you can see on pic KNN is weak on all age stages. Testing accuracy is only 27%. And balancing labels didn’t much affect to KNN prediction. The best stage that predicts KNN is Early Adulthood (Ages 21-35) 59%. Logistic Regression on stages 3 and 4 (6 to 11 ages) on both balanced and unbalanced labels predict very low. However, on almost all group of ages balancing labels play a better prediction role except stage 1. Stage 1 had better prediction on unbalanced labels. Testing accuracy is 46%. The Logistic Regression confusion matrix you can see on pic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3068a22c-13de-46a1-aa24-13ba8b765f7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3450dfaa-d9c4-44f2-8398-bb6bbcc54c0b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dcf296-a336-4bc7-8a11-061e4129b37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d56a646-0ef1-4041-bb90-66d86613f4f4",
   "metadata": {},
   "source": [
    "# Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1a5b3-de40-4302-8501-3182bc7dcce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afc89917-1a55-414d-961f-9b0cf365f88a",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb54d4-d684-437b-b17d-5f5da5249f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c029bf-33fa-4643-8a92-a7e73c528f5f",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f5ffda-1190-4406-972d-85d1fdccbdf9",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Wang, L., &amp; Rajan, D. (2020, June 26). An image similarity descriptor for classification tasks. Journal of Visual Communication and Image Representation. Retrieved May 22, 2022, from https://www.sciencedirect.com/science/article/pii/S1047320320300985?casa_token=hgph9GEVymkAAAAA%3AXpMKKoIT21hFFDJYO3DwyeC1IH3QsWGg6KN27ir5GUs30az1xgc_OAXCYlh20T7nxrwlcKBGnIc </li>\n",
    "    <li>Kumar, V. (2020, July 1). Age Prediction using Image Dataset using Machine Learning (K. Vijay, Ed.) [Review of Age Prediction using Image Dataset using Machine Learning]. Research Gate; Research Gate. https://www.researchgate.net/publication/343162970_Age_Prediction_using_Image_Dataset_using_Machine_Learning\n",
    "        ‌</li>\n",
    "    <li>Khaung Tin, H. H. (2012, May 12). Subjective Age Prediction of Face Images Using PCA (H. H. Khaung Tin, Ed.). Research Gate; International Journal of Innovative Technology and Exploring Engineering (IJITEE). https://www.researchgate.net/publication/263547273_Subjective_Age_Prediction_of_Face_Images_Using_PCA\n",
    "‌</li>\n",
    "    <li>MAICS 2016. (2016, June). Comparison of recent machine learning techniques for gender recognition ... Research Gate. Retrieved May 24, 2022, from https://www.researchgate.net/profile/Joseph-Lemley/publication/301780360_Comparison_of_Recent_Machine_Learning_Techniques_for_Gender_Recognition_from_Facial_Images/links/5727ecda08aee491cb414eb9/Comparison-of-Recent-Machine-Learning-Techniques-for-Gender-Recognition-from-Facial-Images.pdf </li>\n",
    "    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b6a5e-c4e6-4162-b58c-55a4a3ae3d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
