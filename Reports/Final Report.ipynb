{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37bf97c-72b1-463d-8b93-f9021dd4f8a3",
   "metadata": {},
   "source": [
    "# Race, Age, and Gender Classifcation Improvement Using Feature Engineering on Images\n",
    "<figure>\n",
    "<center>\n",
    "<img src = \"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/images/Screen%20Shot%202022-05-22%20at%204.25.31%20PM.png\" width = 300 height = 300 >\n",
    "<br>\n",
    "    \n",
    "<caption> Image of Faces</caption>\n",
    "</center>\n",
    " <figure>\n",
    "     <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b278f-dc83-49ff-89a5-9cfe2a556c52",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b5c2c-be4b-4277-b1e8-2a66a3ac9529",
   "metadata": {},
   "source": [
    "Facial recognition has long remained one of Data Science's most difficult areas to approach. Whereas other types of data have easy to define features and relative simplicity, facial data includes a great deal of hidden or noisy information. Due to this, facial recognition remains a daunting field with no single approach guaranteed to achieve the desired result. And although the human brain excels at instinctively deriving difficult to define features at a glance, programs still struggle to extract something as basic as gender. Yet, should a model be developed that performs as well as humans in all conditions, it would  vastly increase efficiency in all sorts of fields. Basic examples include, medical diagnoses based on facial features, the removal of the need for identification documents, the increased ease of entering one's favorite sites etc. In light of this, the task was to perform exploratory analysis on a number of preprocessing techniques, combined with an analysis of the best performing, and the best performing hyperparameter for said models. Out of four preprocessing techniques (Label Balancing, SIFT,  PCA, RFS) we determined that Label Balancing with oversampling was the best for generalization, while the other techniques lowered training time in exchange for a far greater error rate. Out of four models explored (GBC, CNN, RFS, SVM) as benchmark for the CNN model. CNN was chosen for similar levels of high accuracy in addition to differing training methods. We then determined the best hyperparameters for the model and visualized how each model functioned at peak performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92bb15c-b0ad-435f-aa75-718f3c92aa66",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf151e-8f0c-4547-8e45-c1646affad6f",
   "metadata": {},
   "source": [
    "Image classification techniques are widely apply in the machine learning community and well understood by many. Today's world rely more and more on advance features to protect our identities online and to protect many sensitive information such as SSN and banck accounts. While basic features, such as eye color, nose, etc. are easiily recognisable to the models there are many others that remain still abstract and not easily recognized by the algorithms. Some of this features include age, gender and race.Many models attempt to solve this problems but the criteria and actual performance are still inadequate. Adding these features to the basic features could potencially increase the level of security in face recognision applications. The combinations of unique physical features combined with other variables like age, gender and race could add an extra layer of security protection to any application that needs this for sensible online transaction and for our right to privacy while online. \n",
    "<br>\n",
    "<br>\n",
    "Based on previous workd done on the field it is clear that there is no one way to solve this problem. There is a diversity of algorithms apply to solve this problem as well as a diversity of benchmarks to asses test performace. In this project the focus was on Neural Networks. Moreover, an emphasis was applied to data engineering and various pre-processing techniques.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e83faf-25d3-4264-ad29-9abd02605dbd",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b10c7e-1528-49ff-b306-64dbfee8e216",
   "metadata": {},
   "source": [
    "The field of image classification on human faces is a well studied field and has had many contributions from the scientific community.This project is inspired by many of the approaches used by these scienctist. Some of the most accurate classfication methods are done using CNN and VLAD scheme combined [5]. This is because most of the CNN features focus on the \"salient object of the images and ignores the variation information\" [5]. In other words, CNN model focuses primarilly in the most important features only to classify the images accurately. Many works are exploiting this property of CNN to use it as feature selection method but in this project we mainly use it as classsifcation model. Moreover, we focus on some of the pre-porcessing methods used by Li et al. [5] like BoVW models such as SIFT to preprocess the data. For this project this step is apply to the CNN model only. Many other apporaches were used by Li et al. on such as applying the solution to the L1-norm optimization problem that  Wang et al. develop to locality-constrained linear coding (LLC). That could be one potencial aspect to include for future work. Applying the VLAD scheme could also be an insteresting way to further expand this work. Another relevant work was done by Wang et al. where the primary focus of their research was to determine if one face was younger than another face. The researchers used the same data set that is being utilized in this project and applied a novel correlation between the histograms of the feature map of the two images[1]. With the implemetation of VLAD enncoding and using 128 clusters the researches achieve an accuracy score of 91%. wag et al. pre-process their data by aligning the images and using SVM 10-fold cross validationto get an accuracy of 98.3%. In this project a PCA feature reduction is applied combined with a reduce feature values produced by Haar Cascade algorithm. Other models explore for this research and widely used as images classification methods include random forest classifier, Gradient Boosted Decision trees and support vector machines. Most of these models are usually outperformed by CNN and RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5643b37b-1ae1-451c-ae62-3578780a7c40",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f89905-f82a-4181-b353-7750ea736896",
   "metadata": {},
   "source": [
    "The Dataset was taken from Kaggle and could be uploaded in this <a href = \"https://susanqq.github.io/UTKFace/\">link</a>. The Faces dataset contains 20000+ cropped & aligned facial images with age, race and gender labels. Age label modified to 9 stages based on The Stages  of Human Life Cycle. Project has 6000 testing examples 3500 validation and 10500 training. After balancing training examples, we took 5000 samples proportionally. The pixel values are integer between 0 and 255. To normalize data, we divide it by 255. Each image has a shape of (200,200,3). Feature extracted by PCA.\n",
    "The UTKFACE data set consist of 20000 labeled images. The images's labels consist of the target variables of age, gender and race. The age in the set ranges from 0-116 years old. The gender is 0 for make and 1 for female, and race from 0-4.\n",
    "<ul>\n",
    "    <li>[age] is an integer from 0 to 116, indicating the age</li>\n",
    "    <li>[gender] is either 0 (male) or 1 (female)</li>\n",
    "<li>[race] is an integer from 0 to 4, denoting White, Black, Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern).</li>\n",
    " </ul>\n",
    " \n",
    "The data set consits of mainly two categories, \"in the wild image set\" which are pictures of people with different backgrounds and settings and \"cropped images\" which are images were the face of each person was cropped to exclued as much of the bacground as possible. In this project the latter was used to train and test the models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b4960e-d64f-4db8-a235-434e89217e31",
   "metadata": {},
   "source": [
    "# Methods/Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b8fba0-d71f-412c-ac82-92cd00ba45ac",
   "metadata": {},
   "source": [
    "#### Balancing Labels\n",
    "Balanced labels provide as more accuracy prediction. Unbalanced labels could be a case of undersampling or oversampling as well as incorrect  minority class classification could be a cause of huge issues.\n",
    "On the pic. 1 and 2 you can see how labels looks before and after balancing. Late Childhood (Ages 9-11)has the least samples. Class Early Adulthood (Ages 21-35) and v has the most samples. To implement the balancing we use the SMOTE Technique. The main idea of the SMOTE algorithm is to analyze the minority samples and artificially synthesize new samples based on the minority samples to add to the dataset the flow of the algorithm is as follows:\n",
    " 1. For each sample x in the minority class, use the Euclidean distance as a standard to calculate the distance from it to all samples in the sample set of the minority class to get its k nearest neighbors.\n",
    "\n",
    " 2. Set the sampling factor to determine the sample increase N according to the sample imbalance factor. For each minority sample x, randomly select several samples from the k nearest neighbors, assuming that the chosen nearest neighbor is xn.\n",
    "\n",
    " 3. For each randomly chosen neighbor xn, create a new sample with the original sample according to the following formula. During the balancing the classes move to (-1) stage.\n",
    " \n",
    "Below are the values used for the balanced labels\n",
    "\n",
    "  - #1 infancy (0-2)                                    #0 infancy (0-2)\n",
    "  - #2 Early Childhood (Ages 3-5)                       #1 Early Childhood (Ages 3-5)\n",
    "  - #3 Middle Childhood (Ages 6-8)                      #2 Middle Childhood (Ages 6-8\n",
    "  - #4 Late Childhood (Ages 9-11)                       #3 Late Childhood (Ages 9-11)\n",
    "  - #5 Adolescence (Ages 12-20)                         #4 Adolescence (Ages 12-20)\n",
    "  - #6 Early Adulthood (Ages 21-35)                     #5 Early Adulthood (Ages 21-35)\n",
    "  - #7 Midlife (Ages 36-50)                             #6 Midlife (Ages 36-50)\n",
    "  - #8 Mature Adulthood (Ages 51-79)                    #7 Mature Adulthood (Ages 51-79)\n",
    "  - #9 Late Adulthood (Age 80+)                         #8 Late Adulthood (Age 80+)\n",
    "\n",
    "\n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/images/unbalanced age.png/\">\n",
    "            <figcaption>Fig.1 unbalanced Age label</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/images/balanced age.png/\">\n",
    "            <figcaption>Fig.2 balanced Age label</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<h3>SIFT</h3>\n",
    "A technique for simplifying the complexity of an image by transforming it into a histogram of commonly found features. The features within an image are defined as keypoints within the SIFT algorithm. A key point is defined as a local extrema within an image that is found by comparing a pixel with its neighbors for drastic shifts in pixel values. Next, a descriptor is taken of the local area around each key point which consists of a 128 bin feature vector. This vector describes the local area and a direction, allowing the keypoint to be applicable despite rotation. 128 bin descriptors are collected from training images and clustered via K-means to produce common descriptors. Then each image can be transformed into a histogram with each bin representing the number of times a common feature was detected within the image.\n",
    "\n",
    "One of the techniques used in this project was SIFT, which stands for Scale Invariant Feature Transform. Th reason for using this algorithm to our images is because SIFT's ability to detect major key points in an image. This is particularly useful for the three features we're focusing on in this project (age, gender, and age). The SIFT program is particularly useful because the quality of the images and angle of them have a known low inpact on the prediction of key features in the images. The algorithm was implemented as benchmark results anaylsis as it one of the most use algorithms use for facial recognition.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/Reports/figures/Screen%20Shot%202022-05-24%20at%202.02.26%20PM.png\" width = \"200\" height = \"200\">\n",
    "    <br>\n",
    "<caption> Fig. 3 SIFT Facial Attributes Recognition</caption>\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "<h3>Haar Cascade</h3>\n",
    "Haar Cascade is an object detection algorithm. The algorithm selected important features from the images and bounds them into squares. The number of features scalate very quickly. Because of the high number of features created with theis program the Adaboost algorithm is used to select only the most important features. Adaboost does this by using a collection of weak classifers to create a strong classifier. In this project the Haar Cascade algorithm was trained with the haar cascade collection of face recognition images in their library. The goal of using Haar Cascade was to find the bounds of the faces in the images and zero out all of the pixels outside of the face boundary. This was done with the goal of maximizing the features pass onto each model and reducing surrounding noise and objects.\n",
    "<center>\n",
    "<img src = \"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/jen_branch/images/Haar_Cascade_image.png\" width = 300 height = \"300\">\n",
    "    <br>\n",
    "<caption> Fig. 4 Haar Cascade Object Recognition</caption>\n",
    "</center>\n",
    "\n",
    "<h3>PCA</h3>\n",
    "Speed is also a primary concern in this project. For this reason selecting only the relevant features of each image was important for the project. The images used for the classification each had the shape (200, 200, 3). In order to reduce the features the rgb portion needed to be removed leaving a 2D matric of an imaged of (200, 200). Once the images was flatten the matrix became an array with 40000 values. After applying the PCA algorithms it was determined that if 196 features were kept, above of 90% of the variance could be preserved. This feature reduction technique was apply to every image to speed the classification process.\n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/images/PCA.png\"/>\n",
    "            <figcaption>Fig. 5 PCA Feature Extraction</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    \n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<h3>Random Forest </h3>\n",
    "Random forest algorith was also analyzed to compared with theother models for accuracy and for benchmark testing perfromance. Accuracy for the age labels is pretty low as seen in fig 6 below with an accuracy of 49%.\n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/images/Screen%20Shot%202022-05-25%20at%205.08.27%20PM.png\">\n",
    "            <figcaption>Fig. 6 RFC on Age Labels</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    \n",
    "</table>\n",
    "Similarly for gender we have a low classification score of 68%\n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/images/Screen%20Shot%202022-05-25%20at%205.15.03%20PM.png\">\n",
    "            <figcaption>Fig. 7 RFC on Race Labels</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    \n",
    "</table>\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c1e55-82eb-44d0-a8f9-ff9b4b0e9cbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gradient Boosting for classification\n",
    "\n",
    "\n",
    "Gradient Boosting Classifier is a model combine all the weak models together to a strong single model. Gradient boosting is a successive model learns from the mistakes which from the ones before it. We built a Gradient Boosting model with n_estimators equals to 500, learning rate is 0.05, max_features is 5, and max_depth is equal to 3. Then We applied this model to predict the target variable age with feature extraction PCA, feature selection RFS under unbalance labels and balanced labels. \n",
    "After balanced the age labels, we sampled 5000 images and applied our Gradient Boosting model on this sampling dataset. We got the test accuracy score 0.45. As we can see, according to the comfusion matrix and classificstion report table on fig 8 and 8. The model did a better job on the age label 0 and 5, 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc8971-f46b-482a-80bd-d285984f878b",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/images/GB age label comfusion matrix.png/\">\n",
    "            <figcaption>Fig. 8 GB age label comfusion matrix</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/images/GB on age label classification reprot.png/\">\n",
    "            <figcaption>Fig. 9 GB on age label classification report</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef4f7c4-e8cf-4bf0-ad59-d1e3a962c3ab",
   "metadata": {},
   "source": [
    "<h3>Support Vector Machine</h3>\n",
    "SVM used as the classification task. The main difference from the other classification algorithms in that it chooses a decision boundary, which maximizes the distance from the nearest data points of all classes. SVM doesn't just find a decision boundary; he finds the most optimal decision boundary. Support Vector Regression estimates the coefficients by minimizing the quadratic loss. So, I our case if predicted value falls into the area of the hyperplane the losses are equal 0.  The accuracy score is 43%. This might be due to the linear properties of the model. The best prediction was made for 6 Early Adulthood (Ages 21-35). And mostly on all our models ages 5 to 9 were predicted very low.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf7b33-13cf-4a65-a88d-4ab6655ee2f1",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/images/cm_svr.png/\">\n",
    "            <figcaption>Fig. 10 SVM comfusion matrix</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "  \n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7be58-98d5-4986-95df-da3d55639121",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Dummy Model Comparison</h3>\n",
    "For this project several methods were apply to test the accuracy of the model. One important component that many computer scientist miss is that of comparing their model with a random guessing algorithm. The dummy functions develop attempt to answer, is the model really classifiying methods correctly and are the predictions better than random guessing alone. In figure x is observed the low accuracy value of 14%. Compare to both our models this percentage is low and tell us that our models are indeed doing better than random guessing. The model was implemented by following the balanced labels on age, using a random generator object, and adding more weight to the labels that were repeated the most in the data. The labels are coded from 1-9 as follows:\n",
    "<ol>\n",
    "    <li> infancy (0-2)</li>\n",
    "    <li>Early Childhood (Ages 3-5)</li>\n",
    "    <li>Middle Childhood (Ages 6-8)</li>\n",
    "    <li>Late Childhood (Ages 9-11)</li>\n",
    "    <li> Adolescence (Ages 12-20)</li>\n",
    "    <li> Early Adulthood (Ages 21-35)</li>\n",
    "    <li> Midlife (Ages 36-50)</li>\n",
    "    <li> Mature Adulthood (Ages 51-79)</li>\n",
    "    <li> Late Adulthood (Age 80+)</li>\n",
    "</ol>\n",
    "\n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/images/Screen%20Shot%202022-05-25%20at%201.56.26%20PM.png\" height =\"300\" width = \"300\" >\n",
    "            <figcaption>Fig. 13 showing the classification report on random guessing of age labels</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>\n",
    "Similarly to age a dummy model was also made to random guess the race labels. On this instace the values were from 0 to 4. As before, weigh was added to the values according to frecuency in the data set. Observed the low accuracy score of 0.08 or 8%. This is a good indication that our models are better than random guessing\n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/images/Screen%20Shot%202022-05-25%20at%201.55.59%20PM.png\" height =\"300\" width = \"300\" >\n",
    "            <figcaption>Fig. 14 showing the classification report on random guessing of race labels</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>\n",
    "Lastly, for the gender labels. Because there are two values, 0 for male and 1 for female, a simple binary random number generator was created to simulate random predictions. As expected the accuracy in the report of the figure below is ~50%. The classfication models are doing better than just random guessing and that is a good point to validate all the work this project encompas. \n",
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"https://raw.githubusercontent.com/usersblock/Facial-Attribute-Classification-by-ML-Algorithms/main/images/Screen%20Shot%202022-05-25%20at%201.55.36%20PM.png\" height =\"300\" width = \"300\" >\n",
    "            <figcaption>Fig. 15 showing the classification report on random guessing of gender labels</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78918425-6fd4-42af-a980-ba9ab3fb2f37",
   "metadata": {},
   "source": [
    "## CNN Classifier Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e87542a-888f-4287-978b-03592898e9f4",
   "metadata": {},
   "source": [
    " Each neural network was run with a maximum of 10 epochs with the optimizer adam and sparse categorical cross entropy loss. A callback was implemented with a patience of 5 and monitored the validation accuracy. This was so that the model would return the weights for the best validation accuracy should the model run for 5 epochs without improvement. Testing will be done on the age variable due to it having the most unbalanced and varied classes.\n",
    "Metrics used will be base accuracy, macro f1-score, macro recall, and macro-precision. This is so that comparison could be made on how the model is doing on the entire validation dataset as well as whether it has equal metrics across all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808975b1-154f-4f79-b944-83d1b3980746",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results on Processed and Pre-processed Images, whas there any improvement?\n",
    "Fig 11 shows the metrics scores on the CNN for the various pre-processing techniques apply to the images. While the unbalanced dataset had greater accuracy than the balanced dataset, the balanced dataset had superior macro precision, recall, and f1-score. Balanced datasets would be chosen from then on.The normalized dataset had worse results in addition to requiring additional memory to store float64 values instead of int8. Raw data should be chosen from then on.All metrics resulting from the preprocessing techniques were worse than corresponding metrics in the non preprocessed balanced dataset. Thus, no preprocessing techniques would be utilized.\n",
    "Verdict: The non-normalized, balanced, non-preprocessed dataset has the best performance out of all iterations with an accuracy of 0.42."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705163b-9ac8-49c5-b51b-a11526e9804c",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"200\">\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/PreProcessingResults.PNG\"/>\n",
    "            <figcaption>Fig.11 Results matrix for preprocessing on validation</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5946e007-5f52-42ab-955b-0797d5aeca9c",
   "metadata": {},
   "source": [
    "### Model Selection based on Hyper Parameter Tuning on CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb460b59-ef4f-448b-9d83-da16b7af5698",
   "metadata": {},
   "source": [
    "Based on initial results, GBC was to be chosen for its high level of accuracy. However, a better Neural Network Structure was discovered which gave an accuracy of 0.48. This is 0.02 above the GBC accuracy of 0.46. Thus, Neural Networks will be utilized for hyperparameter tuning. The selected structure is listed below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0038a58-74f7-4c6b-adc5-b79e636d9489",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ModelSummary.PNG\"/>\n",
    "            <figcaption>Fig. 12 Neural Network Structure</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e89db7-7bfe-492c-89a7-4ce2b4dc4d96",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846943c2-9c3b-4e4f-915f-7bca076c2813",
   "metadata": {},
   "source": [
    " After concluding that a balanced dataset yielded the best performance and that the model itself was the 2nd most accurate, further hyperparameter tuning was needed to achieve a global maximum of performance. Five hyperparameters were tuned for the following runs: Dropout, L1 Regularization, L2 Regularization, Learning Rate, and Number of samples. A hyperparameter would only be considered if its accuracy was greater than the base model by more than 0.01. This threshold is to ensure that improvements are not due to changes in sampling and are instead because the model genuinely improved.\n",
    "#### Base Model's Hyperparameters\n",
    "##### - Dropout: 0\n",
    "##### - L1: 0\n",
    "##### - L2: 0\n",
    "##### - Lr: 0.001\n",
    "##### - Sampling Size: 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de11d3-1987-4014-a3fa-6a90a093ce26",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a2552-f31d-4555-9635-3a78a411e5be",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/L2Report.PNG\"/>\n",
    "            <figcaption>Fig.16 L2 hyperparameter tuning values</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/L1Report.PNG\" />\n",
    "            <figcaption>Fig.17 L1 hyperparameter tuning values</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/DropoutReport.PNG\" />\n",
    "            <figcaption>Fig.18 Dropout hyperparameter tuning values</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/LrReport.PNG\" />\n",
    "            <figcaption>Fig.19 Learning Rate hyperparameter tuning values</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7965b295-a7d9-44df-8ccd-75769ed706f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Based on hyperparameter tuning on all models, L1: 0.001 and Lr: 0.0001 were the best candidates since their accuracy was beyond 0.01 of the base accuracy of 0.485552."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68449cf6-6e1f-46a6-9276-5f6ad892716e",
   "metadata": {},
   "source": [
    "### Sample Size Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07377eae-70f7-4438-8a56-9881bf2e0452",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/SampleAcc.PNG\"/>\n",
    "            <figcaption>Fig.20 Sample Size hyperparameter tuning versus accuracy</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/SampleLoss.PNG\" />\n",
    "            <figcaption>Fig.21 Sample Size hyperparameter tuning versus loss</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae66871-fa47-42f5-bfff-1c9e0bf2b604",
   "metadata": {
    "tags": []
   },
   "source": [
    " Sample size amounts were tested from 500 to 8000 in intervals of 500 on the age labels of teh data set. It was found that 5000 had the highest accuracy. Like before, the model loss seems to inversely correlate with the model's accuracy. Although the model was most accurate on 5000 samples, we will be using the 8000 as using more data is best practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031bbea-7987-4214-9170-1d8e38e3968f",
   "metadata": {},
   "source": [
    "### Post Hyperparameter testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b5de5-1e0a-43fb-a213-b85733f0bde2",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/8000TestRaceReport.PNG\"/>\n",
    "            <figcaption>Fig.22 Classification report for the race test set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/8000TestReport.PNG\" />\n",
    "            <figcaption>Fig.23 Classification report on the age test set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/HyperparameterTuning/8000TestGenderReport.PNG\" />\n",
    "            <figcaption>Fig.24 Classification report on the gender test set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a0465d-cad8-46d2-ba2c-6c05e6257eec",
   "metadata": {},
   "source": [
    "After some basic runs, it was discovered that LR: 0.0001 had the best validation accuracy at 0.61 and a test accuracy of 0.62. The classification report on age shows far better results than that of the control model. In addition, the race and gender model using the same neural network structure achieved better results than the dummy models. Thus, this model was to be considered satisfactory. The only thing left to do was to visualize the weakpoints of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e4ca7c-1d19-4ff8-88ea-e7fbd15b2e9d",
   "metadata": {},
   "source": [
    "### Feature extraction by analyzing mislabeled classifications\n",
    "Below are samples of images taht were classfied correctly by the CNN model. The first half is of labels that were correctly identified while the bottom images were misclassfied by the algorithm. They are order by the labels on the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15effb-c336-4469-a291-c6d9464087f5",
   "metadata": {},
   "source": [
    "#### Age "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b772b-1825-42cb-9c4e-9789b2d0b94b",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/C15.PNG\"/>\n",
    "            <figcaption>Age Bracket: 5</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/C21.PNG\" />\n",
    "            <figcaption>Age Bracket: 1</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/C38.PNG\" />\n",
    "            <figcaption>Age Bracket: 8</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/IC14.PNG\"/>\n",
    "            <figcaption>Correct Label: 4 Predicted Label: 5</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/IC20.PNG\" />\n",
    "            <figcaption>Correct Label: 0 Predicted Label: 1</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Age/IC35.PNG\" />\n",
    "            <figcaption>Correct Label: 5  Predicted Label: 8</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6692c-b606-4e4a-939e-796231945d38",
   "metadata": {},
   "source": [
    "#### Race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befcbc6e-0906-42b8-9669-38307900473d",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/C13.PNG\"/>\n",
    "            <figcaption>Race: Indian</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/C22.PNG\" />\n",
    "            <figcaption>Race: Asian</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/C31.PNG\" />\n",
    "            <figcaption>Race: Black</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/IC10.PNG\"/>\n",
    "            <figcaption>Correct Label: White Predicted Label: Indian</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/IC24.PNG\" />\n",
    "            <figcaption>Correct Label: Other(All other races in this category) Predicted Label: Asian</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Race/IC33.PNG\" />\n",
    "            <figcaption>Correct Label: Indian  Predicted Label: Black</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dca749-0bce-4fcf-9522-28de486223c0",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e307e4-7ca8-4cc5-aad0-a83be55175c0",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Gender/C11.PNG\"/>\n",
    "            <figcaption>Gender: Female</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Gender/C20.PNG\" />\n",
    "            <figcaption>Gender: Male</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Gender/IC10.PNG\"/>\n",
    "            <figcaption>Correct Label: Male Predicted Label: Female</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"200\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/ClassificationIssues/Gender/IC21.PNG\" />\n",
    "            <figcaption>Correct Label: Female Predicted Label: Male</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af76eb1e-e2e8-4406-a617-27ac358eb1dc",
   "metadata": {},
   "source": [
    "#### Features extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a21e2-ae4f-4057-b71d-e840c5bd7030",
   "metadata": {},
   "source": [
    "How the model performs feature extraction can be analyzed by comparing the misclassifications. \n",
    " On the age model, it tends to use features associated with the facial edges or facial shape. This is evidenced by the similarity of wrinkles on the third pair, the smoothness of face on the first pair, and the round facial shape of the second pair.On the race model, it mostly seems to use facial shape when determining racial features. Interestingly enough, skin color does not seem to be a factor in determining race for the model.\n",
    "On the gender model, it is difficult to tell what the model is using to determine gender and this presents poinst for future research on this project. The second pair disproves that the model is using facial shape as the main feature. In addition, both image pairs have different tones and different winkle edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a32a9f0-b52a-4a57-947d-8144ec080f4a",
   "metadata": {},
   "source": [
    "### Final Comparison between Neural Networks, Dummy Model, Simple Models, and Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b02e2-c57a-4307-87f2-5fbecf3fac5b",
   "metadata": {},
   "source": [
    "Based on the age metric, the hyperparameter tuned neural network with Lr: 0.0001 outperforms all other models. The final age accuracy for the neural network was 0.62. If we compare to the simple models, KNN has a testing accuracy of 0.27 and Logistic Regression has a testing accuracy of 0.46. When we compare to the dummy model, it has an accuracy of 0.14."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3450dfaa-d9c4-44f2-8398-bb6bbcc54c0b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801b482-8f5b-4c2c-8281-8b3d0defa0df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "In all metrics, the Neural Network with hypertuning outperformed all other models. There was enough data to train each model on. However, the lack of memory within the testing machine limited the images trained to 5000 instead of potentially 60000 images in the fully balanced dataset. Based on the image misclassifications, the model seems to mainly use facial shapes, wrinkles, and smoothness as features. Future work to be done would be to find a way to simplify the dataset to train more samples while retaining most of the information similarly to what Wang et al. used on their imagage classfication work on age classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56a646-0ef1-4041-bb90-66d86613f4f4",
   "metadata": {},
   "source": [
    "# Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91221578-b44a-4668-aef6-bcd80dfd9f2f",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/GitCommitsandlines.PNG\"/>\n",
    "            <figcaption>Commits/additions/deletions per person</figcaption>\n",
    "        </figure>\n",
    "</tr>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "    ofirsov000 : Oxana Firsova\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "    jvivar2383 : Jenifer Vivar\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "    usersblock : Thomas Ly\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "    yxiang001 : Yinzi Xiang\n",
    "    </td>\n",
    "</tr>    \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3acc832-a485-4d31-9c47-1bc7670dfa9d",
   "metadata": {},
   "source": [
    "## Individual Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340de9e5-a410-4e30-b559-6474195544f9",
   "metadata": {},
   "source": [
    "#### Oxana Firsova"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad3e92-6ee3-4ef3-b6d7-76039e7cdcd2",
   "metadata": {},
   "source": [
    "##### Balanced all labels by applying SMOTE Technique. Splitting age label into 9 stages based on the Human Life Cycle.  Implement SVM algorithm. Applied masks on SVM and test accuracy score. Compare the accuracy on SVM with Sift and without. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1633dde9-f86e-4e3d-9984-152241787eb8",
   "metadata": {},
   "source": [
    "#### Jenifer Vivar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671db3b2-d95d-41f3-8144-e0fe56d63fff",
   "metadata": {},
   "source": [
    "##### Added pre-processing techniques like Hair Cascade and several images filters (later discarded) for apply to the images before using them for the classier. I also, implemented a Random Forest algorithm and test the accuracy scores on the process and preprocess data to later compared with other models my group members were working on. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b2433-a69a-4e07-9b47-133074a6e73f",
   "metadata": {},
   "source": [
    "#### Thomas Ly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ec7dd-971c-4cca-b1ec-92e07d29b4a6",
   "metadata": {},
   "source": [
    "##### Implemented the SIFT slgorithm to extract image features and simplify dimensions. Implemented the Convolutional Neural Network and preprocessed the dataset to find the best dataset for Neural Network. Hyperparameter tuned the Neural Network and performed feature extraction on the images based on misclassified examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b096f9-e7e8-414c-be25-0a06caaaa3d1",
   "metadata": {},
   "source": [
    "#### Yinzi Xiang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b772183-69f5-40c8-9e30-655c6118dbf5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Explore the feature extraction PCA and feature selection Random Forest feature selection. Explore, set and study the model of Gradient Boosting Classifier. Applied this model with feature extraction like PCA, shift and RFS under balanced and unbalanced labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c029bf-33fa-4643-8a92-a7e73c528f5f",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda313e-3e2d-4321-80b1-2c83acbfa637",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Wang, L., &amp; Rajan, D. (2020, June 26). An image similarity descriptor for classification tasks. Journal of Visual Communication and Image Representation. Retrieved May 22, 2022, from https://www.sciencedirect.com/science/article/pii/S1047320320300985?casa_token=hgph9GEVymkAAAAA%3AXpMKKoIT21hFFDJYO3DwyeC1IH3QsWGg6KN27ir5GUs30az1xgc_OAXCYlh20T7nxrwlcKBGnIc </li>\n",
    "    <li>Kumar, V. (2020, July 1). Age Prediction using Image Dataset using Machine Learning (K. Vijay, Ed.) [Review of Age Prediction using Image Dataset using Machine Learning]. Research Gate; Research Gate. https://www.researchgate.net/publication/343162970_Age_Prediction_using_Image_Dataset_using_Machine_Learning\n",
    "        ‌</li>\n",
    "    <li>Khaung Tin, H. H. (2012, May 12). Subjective Age Prediction of Face Images Using PCA (H. H. Khaung Tin, Ed.). Research Gate; International Journal of Innovative Technology and Exploring Engineering (IJITEE). https://www.researchgate.net/publication/263547273_Subjective_Age_Prediction_of_Face_Images_Using_PCA\n",
    "‌</li>\n",
    "    <li>MAICS 2016. (2016, June). Comparison of recent machine learning techniques for gender recognition ... Research Gate. Retrieved May 24, 2022, from https://www.researchgate.net/profile/Joseph-Lemley/publication/301780360_Comparison_of_Recent_Machine_Learning_Techniques_for_Gender_Recognition_from_Facial_Images/links/5727ecda08aee491cb414eb9/Comparison-of-Recent-Machine-Learning-Techniques-for-Gender-Recognition-from-Facial-Images.pdf </li>\n",
    "    <li> Li, Q., Peng , Q., &amp; Yan, C. (2017, June 30). 1 multiple Vlad encoding of CNNS. Arrive.org. Retrieved May 19, 2022, from https://arxiv.org/pdf/1707.00058.pdf </li>\n",
    "    \n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
