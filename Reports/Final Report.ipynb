{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8b278f-dc83-49ff-89a5-9cfe2a556c52",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b5c2c-be4b-4277-b1e8-2a66a3ac9529",
   "metadata": {},
   "source": [
    "##### Facial recognition has long remained one of Data Science's most difficult areas to approach. Whereas other types of data have easy to define features and relative simplicity, facial data includes a great deal of hidden or noisy information. Due to this, facial recognition remains a daunting field with no single approach guaranteed to achieve the desired result. And although the human brain excels at instinctively deriving difficult to define features at a glance, programs still struggle to extract something as basic as gender. Yet, should a model be developed that performs as well as humans in all conditions, it would  vastly increase efficiency in all sorts of fields. Basic examples include, medical diagnoses based on facial features, the removal of the need for identification documents, the increased ease of entering one's favorite sites etc. In light of this, the task was to perform exploratory analysis on a number of preprocessing techniques, combined with an analysis of the best performing, and the best performing hyperparameter for said models. Out of four preprocessing techniques (Label Balancing, SIFT,  PCA, RFS) we determined that Label Balancing with oversampling was the best for generalization, while the other techniques lowered training time in exchange for a far greater error rate. Out of four models explored (GBC, CNN, RFS, SVM), GBC and CNN were chosen for similar levels of high accuracy in addition to differing training methods. We then determined the best hyperparameters for each model and visualized how each model functioned at peak performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92bb15c-b0ad-435f-aa75-718f3c92aa66",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd292b33-4723-4367-a556-b5218b80eb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94e83faf-25d3-4264-ad29-9abd02605dbd",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec95d81-c70d-42ca-be3b-ba29099794dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5643b37b-1ae1-451c-ae62-3578780a7c40",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f89905-f82a-4181-b353-7750ea736896",
   "metadata": {},
   "source": [
    "##### The Dataset was taken from Kaggle and could be uploaded in this link. The Faces dataset contains 20000+ cropped & aligned facial images with age, race and gender labels. Age label modified to 9 stages based on The Stages  of Human Life Cycle. Project has 6000 testing examples 3500 validation and 10500 training. After balancing training examples, we took 5000 samples proportionally. The pixel values are integer between 0 and 255. To normalize data, we divide it by 255. Each image has a shape of (200,200,3). Feature extracted by PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b4960e-d64f-4db8-a235-434e89217e31",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf824c9-17b8-4e76-99c3-af4ae3571ccf",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db428b67-d2a2-4ae8-8866-93c9b7552211",
   "metadata": {},
   "source": [
    "### Balance via Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7c49d-b1d6-415e-b6e9-d95be3537303",
   "metadata": {},
   "source": [
    "### SIFT - (Scale Invariant Feature Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ef4ba-7018-4b24-a721-0fed720d6280",
   "metadata": {},
   "source": [
    "##### A technique for simplifying the complexity of an image by transforming it into a histogram of commonly found features. The features within an image are defined as keypoints within the SIFT algorithm. A key point is defined as a local extrema within an image that is found by comparing a pixel with its neighbors for drastic shifts in pixel values. Next, a descriptor is taken of the local area around each key point which consists of a 128 bin feature vector. This vector describes the local area and a direction, allowing the keypoint to be applicable despite rotation. 128 bin descriptors are collected from training images and clustered via K-means to produce common descriptors. Then each image can be transformed into a histogram with each bin representing the number of times a common feature was detected within the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5581b0b6-2fee-402c-a391-9e601a578730",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd42a83-89da-4961-9135-b18924c323e0",
   "metadata": {},
   "source": [
    "### RFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a5888-20b0-4fd0-8e78-f9773171a567",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e96c4-45ca-4b28-a48e-02a42d6de817",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedc8945-67ff-4af1-ab9d-fcf80866fe9f",
   "metadata": {},
   "source": [
    "##### Each neural network was run with a maximum of 10 epochs with the optimizer adam and sparse categorical cross entropy loss. A callback was implemented with a patience of 5 and monitored the validation accuracy. This was so that the model would return the weights for the best validation accuracy should the model run for 5 epochs without improvement. Testing will be done on the age variable due to it having the most unbalanced and varied classes.\n",
    "##### Metrics used will be base accuracy, macro f1-score, macro recall, and macro-precision. This is so that we may compare how the model is doing on the entire validation dataset as well as whether it has equal metrics across all classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f6b32-7152-4d81-b58c-e9493f27c49a",
   "metadata": {},
   "source": [
    "#### Unbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa572c2-330b-4b33-be39-0d28c67bcf9a",
   "metadata": {},
   "source": [
    "##### Although not recommended, the effects of an unbalanced dataset towards a model should be investigated. The effects of the raw dataset upon various metrics are illustrated in the figures below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c574a05-3962-40c9-8b4c-c9c716fcd88e",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/UnbalancedModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.1 Classification report for the validation set on age</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/UnbalancedModel/ConMatValAge.PNG\" width=\"400\" />\n",
    "            <figcaption>Fig.2 Classification Matrix on the validation set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/UnbalancedModel/ModelAcc.PNG\" width=\"400\" />\n",
    "            <figcaption>Fig.3 Model Accuracy per Epoch</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ccbae9-3304-41d4-a186-1ef0d9bd6614",
   "metadata": {},
   "source": [
    "##### For figure 1 accuracy of 0.56 better than all other models. However, note the f1 scores for classes 1,2, 3 compared to the f1 scores for class 0, 5, 6, 7. Classes 1, 2, 3 were the least frequent labels, while classes 0, 5, 6, 7 were far more common. Since the least common classes have no predictions whatsoever, we can conclude that the model did not receive enough training labels for those classes. Another important metric to consider is the macro avg, which is the average accuracy across all classes if weighted the same. This will be compared to the next model which will have balanced classes.\n",
    "##### Figure 2 further illustrates the issues presented in the classification report. The matrix clearly shows how most predictions by percentage were clustered around the most common labels.\n",
    "##### Figure 3 can be considered deceptive if one did not check the classification report. Although it displays high accuracy compared to later dummy models, it shows total accuracy which favors the larger classes by default.  {DO AGAIN}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f310550f-c4a9-4086-a554-ebfba2cae684",
   "metadata": {},
   "source": [
    "#### Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3488e829-877d-412d-88f5-4f99386d64cd",
   "metadata": {},
   "source": [
    "##### This dataset was created via the oversampling of unbalanced class labels until they reached the quantity of the most frequent class. Then, a balanced sampling of 5000 was taken from these labels. The results of the model training are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d755d6b5-a6b7-4ef0-b21d-16893f87ac17",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/BalancedModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.4 Classification report for the validation balanced set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/BalancedModel/CLMatrixVal.PNG\" />\n",
    "            <figcaption>Fig.5 Classification Matrix on the validation balanced set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/BalancedModel/AccPlot.PNG\" />\n",
    "            <figcaption>Fig.6 Model Accuracy per Epoch</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b002f2e5-0dae-4566-b8e1-636080cd7c16",
   "metadata": {},
   "source": [
    "##### Analyzing figure 4, the accuracy is far lower than the unbalanced dataset. However, the macro average is far higher compared to the unbalanced model. In addition, the least common labels are being predicted to a far greater extent than the unbalanced model. While the most common labels have a lower accuracy, this is only because the model isn't blindly predicting the most common labels to be correct.\n",
    "##### As for figure 5, the prediction distribution is far more balanced compared the the unbalanced dataset. This is important as the model is meant to predict all labels well, not just one. \n",
    "##### Figure 6 displays the main issue that preprocessing and hyperparameter tuning will attempt to address. Due to limited memory, only 5000 samples may be trained at maximum. Naturally, this has caused great levels of overfitting in the attempt to classify (200,200,3) images. In addition, it also shows the model overfitting within the first half and plateauing afterwards.\n",
    "##### Overall, using a balanced dataset is necessary for generalization and later runs will attempt to address overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225564bf-14d0-4c9c-b77f-7c6bbf48fdaf",
   "metadata": {},
   "source": [
    "#### Normalized Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b50db04-379f-411d-a62a-2a9b1ce54941",
   "metadata": {},
   "source": [
    "##### Each image was normalized in accordance to its highest and lowest pixel values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b9c77-bc55-49e8-827b-bdc0e3b98252",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/NormalizedModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.7 Classification report for the validation normalized set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/NormalizedModel/AccPlot.PNG\" width=\"400\" />\n",
    "            <figcaption>Fig.8 Classification Matrix on the validation normalized set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12425c16-d8b8-4b92-a72f-9d046f713934",
   "metadata": {},
   "source": [
    "##### In figure 7, compared to the control balanced dataset, the normalized dataset is 0.03 less accurate. In addition, the macro accuracy is 0.05 less accurate than the non-normalized dataset on the f1-score. With this, it can be concluded that a non-normalized dataset should be used for the rest of the techniques. What should be noted is that in figure 8, the model has reached maximum accuracy in later epochs, meaning this dataset takes longer to overfit.\n",
    "##### Despite this, the normalized dataset's overall performance has indicated that is it a poor preprocessing technique for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa75753-7c0c-47f1-88c1-01acea16a274",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a913e8a-5be8-417a-bc71-25a7ba203709",
   "metadata": {},
   "source": [
    "##### For the PCA dataset, the image arrays were first flattened into the shape of (1,120000). When running the training images through the PCA dimension reduction technique, PCA was initialized to only keep enough components to reach a minimum of 0.90 explained variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c486ca-dcf0-4172-b31e-a19dc6614a42",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/PCAModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.9 Classification report for the validation PCA set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/PCAModel/ValMatrix.PNG\" />\n",
    "            <figcaption>Fig.10 Classification Matrix on the validation balanced set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f507cf3-bd0a-4cef-b136-8bf389e3775f",
   "metadata": {},
   "source": [
    "##### Based on the accuracy and macro averages on figure 9, it is clear that the PCA dataset performs poorly compared to the balanced dataset. This is despite the fact that 0.90 explained variance was present within the dataset.\n",
    "##### The reasoning becomes clearer when looking at figure 10. However PCA affected the dataset, it has resulted in the model predicting mostly on label 5, the most common one. Thus, PCA should not be included in Neural Network's preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f60523-af15-4194-ad50-12a61f51a7e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### RFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dcb479-81c9-46e8-8d59-0ceb651ae67c",
   "metadata": {},
   "source": [
    "##### Random Forest Selection is an ensemble method used for feature selection. It does so by utilizing a number of Decision trees and calculating how much each feature decreases the impurity. From all the trees, it can determine the importance of a feature. Lastly, RFS returns the features that have a greater importance than the mean importance. Out of 120,000 pixel features, RFS chose 36,407 features. This is nearly 1/4th of the original dataset's complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe711e9a-0dc9-4afd-a4c4-c9474994b112",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/RFSModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.11 Classification report for the validation RFS set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/RFSModel/LossPlot.PNG\" />\n",
    "            <figcaption>Fig.12 Loss plot for validation RFS set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ec8efe-ed35-4458-bd29-07ad2cd0e072",
   "metadata": {},
   "source": [
    "##### Compared to the balanced model, RFS achieves slightly worse results. The accuracy differs by -0.03 and the macro average differs by -0.02 for the f1 score. While RFS won't be used for hyperparameter tuning for the sake of higher accuracy, it can serve as a reliable and small dataset.\n",
    "##### According to figure 12, the model learns quickly as evidenced by the training line. While the line does plateau by epoch 10, the model achieves near perfect accuracy by the end. However, the validation line suggests that the model does overfit early like the other models. Thus, it is unlikely that this solves the overfitting issues present in the control balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5a0ab-1348-4477-b182-f26df34e6420",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### SIFT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5abdd-0ab3-49ca-9910-502b19430ab4",
   "metadata": {},
   "source": [
    "##### SIFT is a form of feature selection which simplifies images into histograms of commonly found image feaures. It does so by finding common image descriptors in the training set and utilizing the common descriptors to transform all images into histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e94a6c-e9a4-4d56-9d63-671bebe7ee8e",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/SIFTModel/CLValReport.PNG\"/>\n",
    "            <figcaption>Fig.13 Classification report for the validation SIFT set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "    <td width=\"500\">\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/SIFTModel/ValMatrix.PNG\" />\n",
    "            <figcaption>Fig.14 Classification Matrix on the validation SIFT set</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da14a34-e78a-4966-8780-30163301006c",
   "metadata": {},
   "source": [
    "##### The accuracy and macro f1-score was far lower than the balanced dataset. This suggests that while SIFT did transform the data, it did not keep enough relevant information for the training model to successfully generalize. This is further evidenced by the fact that it has a distributed accuracy, but low accuracy overall. Thus, we will not be using SIFT despite its fast training speed.\n",
    "##### One thing to note from figure 14, is its similarity to the classification matrix on the PCA dataset. From this, it seems that drastically reducing an image's dimensions can cause the model to misclassify most images in favor of the most common classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921e537-ea9b-4111-a241-58bb0db76f21",
   "metadata": {},
   "source": [
    "#### Preprocessing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c748d-51bb-4b60-a024-10bb19c51cf3",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr width = \"2000\">\n",
    "    <td>\n",
    "        <figure>\n",
    "            <img src=\"../Reports/figures/NeuralNetwork/PreProcessingResults.PNG\"/>\n",
    "            <figcaption>Fig.14 Results matrix for preprocessing on validation</figcaption>\n",
    "        </figure>\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba4d500-5604-42e9-9536-f138cac6fc7d",
   "metadata": {},
   "source": [
    "#### Balanced versus Unbalanced\n",
    "##### While the unbalanced dataset had greater accuracy than the balanced dataset, the balanced dataset had superior macro precision, recall, and f1-score. Balanced datasets would be chosen from then on.\n",
    "#### Normalized versus Raw data\n",
    "##### The normalized dataset had worse results in addition to requiring additional memory to store float64 values instead of int8. Raw data should be chosen from then on.\n",
    "#### Balanced versus RFS, PCA, SIFT\n",
    "##### All metrics resulting from the preprocessing techniques were worse than corresponding metrics in the non preprocessed balanced dataset. Thus, no preprocessing techniques would be utilized.\n",
    "#### Verdict:\n",
    "##### The non-normalized, balanced, non-preprocessed dataset has the best performance out of all iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c1855-2a5f-4cf5-b58c-391f32cb6963",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e286b0-23a4-4ce9-83d7-7c65595d4761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3450dfaa-d9c4-44f2-8398-bb6bbcc54c0b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dcf296-a336-4bc7-8a11-061e4129b37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d56a646-0ef1-4041-bb90-66d86613f4f4",
   "metadata": {},
   "source": [
    "# Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1a5b3-de40-4302-8501-3182bc7dcce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afc89917-1a55-414d-961f-9b0cf365f88a",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb54d4-d684-437b-b17d-5f5da5249f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c029bf-33fa-4643-8a92-a7e73c528f5f",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2490961-3d9a-40a7-a5cb-a2d913372784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
